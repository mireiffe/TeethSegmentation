\documentclass[10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{geometry} % to change the page dimensions
\geometry{a4paper}
\usepackage{authblk}

%% Packages
\usepackage{graphicx, subcaption}
\usepackage{amsmath,amssymb,amsthm,amsfonts}
\usepackage{bm}
\usepackage{algorithm, algorithmic}
\usepackage{multirow}
\usepackage{bbm}
\usepackage{hyperref,url}
\usepackage{kotex}
\usepackage[labelformat=simple]{subcaption}

\usepackage{tikz}
\usetikzlibrary{shapes.geometric, arrows, positioning, calc}
\usetikzlibrary{backgrounds}
\usetikzlibrary{arrows.meta}

\tikzstyle{title} = [rectangle, minimum width=3cm, minimum height=1cm, text centered, draw=black, text width=3cm, fill=white!100]
\tikzstyle{startstop} = [rectangle, rounded corners, minimum width=3cm, minimum height=1cm,text centered, draw=black, fill=red!30]
\tikzstyle{io} = [trapezium, trapezium left angle=70, trapezium right angle=110, minimum width=3cm, minimum height=1cm, text width=1.3cm, text centered, draw=black, fill=blue!30]
\tikzstyle{process} = [rectangle, minimum width=3cm, text width=3cm, minimum height=1cm, text centered, draw=black, fill=orange!30]
\tikzstyle{decision} = [diamond, minimum width=3cm, minimum height=1cm, text centered, draw=black, fill=green!30]
\tikzstyle{arrow} = [thick,->,>=stealth]

\captionsetup[figure]{labelsep=period}
% \renewcommand{\thefigure}{\Roman{figure}}
% \captionsetup[subfigure]{labelformat=parens} % default is 'parens'
% \renewcommand{\thesubfigure}{\thefigure.\alph{subfigure}.}
\renewcommand\thesubfigure{(\alph{subfigure})}

%% Theorems
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}

\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{example}[theorem]{Example}

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}

%% Equations
\numberwithin{equation}{section}

%% Algorithms
\renewcommand\algorithmicdo{}
\renewcommand\algorithmicthen{}
\renewcommand\algorithmicendfor{\textbf{end}}

%% Macros
\def\chfun{\mathbbm{1}}
\def\skel{\mathcal{S}}
\def\calc{\mathcal{C}}
\def\sko{\hat{\mathcal{S}}}
\def\ske{\mathcal{S}^8}
\def\endske{E\left(\mathcal{S}^8\right)}
\def\endomc{E\left(\Omega_c\right)}


\def\gphi{\nabla\phi}
\def\ngphi{\left|\nabla\phi\right|}
\def\ngphii{\left|\nabla\phi_i\right|}
\def\fci{F_{c,\,i}}
\def\fcj{F_{c,\,j}}
\def\cm{\, ,}
\def\pd{\, .}

\def\omi{\Omega_i}
\def\oma{\Omega_a}
\def\ome{\Omega_E}
\def\oms{\Omega_S}
\def\omc{\overline{\Omega}_P}
\def\omcc{\Omega_P}
\def\ER{\Omega_{Er}}

\def\opp{\Omega_{\phi_i}^+}
\def\opn{\Omega_{\phi_i}^-}
% \def\opo{\Omega_{\phi}^0}
\def\opo{C_{\phi_i}}

\def\sdf{\mbox{SDF}}

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
% \def\tOmega{\tilde{\Omega}}
% \def\tGamma{\tilde{\Gamma}}
% \def\tV{\tilde{V}}
% \def\W{\mathbb{W}}
% \def\tu{\tilde{u}}
% \def\bu{\bar{u}}
% \def\hu{\hat{u}}
% \def\bl{\bar{\lambda}}
% \def\p{\mathbf{p}}
% \def\P{\mathbf{P}}
% \def\intO{\int_{\Omega}}
% \def\intOs{\int_{\Omega_s}}
% \def\m{\mathbf{m}}
% \def\n{\mathbf{n}}
% \def\blambda{\bm{\lambda}}

% \def\tE{\tilde{E}}
% \def\N{\mathcal{N}}

% \def\div{\mathrm{div}}
% \def\proj{\mathrm{proj}}
% \def\prox{\mathrm{prox}}
% \def\ran{\mathrm{ran}\,}
% \def\ed{\mathrm{ed}}
% \def\supp{\mathrm{supp}\,}
% \def\TOL{\mathrm{TOL}}
% \DeclareMathOperator*{\argmin}{\arg\min}

% Text Color and Strike
\usepackage[normalem]{ulem}
\usepackage{color}
\newcommand{\red}[1]{{\color{red}{#1}}}
\newcommand{\blue}[1]{{\color{blue}{#1}}}

\title{ Individual Tooth Segmentation in Human Teeth Images Using Pseudo Edge-Regions Obtained by Deep Neural Networks }
\author{Seongeun Kim and Chang-Ock Lee}
\affil{Department of Mathematical Sciences, KAIST, Daejeon 34141, Korea}
\date{ }

\begin{document}
\maketitle

\begin{abstract}
In human teeth images taken outside the oral cavity with a general digital camera, it is difficult to segment individual tooth due to common obstacles such as weak edges, intensity inhomogeneities and strong light reflections. In this work, we propose a method for segmenting individual tooth in human teeth images. The key of the method is to obtain pseudo edge-regions using deep neural networks. After obtaining landmarks for each tooth regions in the pseudo edge-region, we apply an active contour model to segment the individual tooth. We also present a strategy using existing model-based methods for labeling the data required for neural network training.
\end{abstract}

{\small \textbf{Key words}
Tooth segmentation, Neural network, Geometric attraction--driven flow, Edge-region, Light reflection}

{\small \textbf{AMS subject classifications}
94A08, 68T07}

%% Main text starts ---------------------------------------------------------------------------------------------------
% Section: Introduction
\section{Introduction}
\label{Sec:Introduction}

Image segmentation is one of major topics in the field of computer vision. The main goal of image segmentation is to segment objects in an image according to a specific purpose and many outstanding methodologies have been developed. The active contour model is one of the popular methods for the image segmentation. It makes the contour surrounding an object move to the boundary of the object with the designed force~\cite{Kass:1988:Snakes}; gradient vector flows~\cite{Xu:1997:GVF}, geodesic active contours~\cite{Caselles:1997:GAC} and balloon forces~\cite{Cohen:1991:Balloon} are well-known models with different forces. There are also variational models that uses statistical information of intensities in an image~\cite{Park:2014:SRM,Zhu:1996:RegCompet}. In \cite{Chan:2001:chanvese}, unlike the previous methods using edge maps, a region-based active contour method was proposed.

Segmentation of individual tooth in human teeth images has been mainly performed on computed tomography (CT) or X-ray images~\cite{Yuan:2020:teethParanomic,Naumovich:2015:teethCT3D,Said:2006:teethxray,Shah:2006:teethautoseg}. Teeth are easily segmented in these CT or X-ray images since the intensity of the teeth region is much stronger than the gums or tissues. However, segmenting individual tooth in a teeth image taken outside the oral cavity with a general digital camera is a more difficult problem. In the teeth images, not only weak edges and light reflections appear, but also colors and illuminance are inhomogeneous due to plaque and oral structure, which are major obstacles to segmentation of individual tooth. Several attempts have been made to segment individual tooth in teeth images. In~\cite{Na:2014LteethMorph} the watershed algorithm~\cite{Vincent:1991:watershed} with color information was proposed. In recent studies \cite{Kim:2020,Pham:2020,Zhu:2020:teethMaskrcnn}, segmentations using deep learning methods based on Mask R--CNN \cite{He:2018:MRCNN} were proposed. In~\cite{WU:2016}, a supervised learning method BEL~\cite{Dollar:2006:BEL} was used to obtain the individual tooth boundaries. Although the model-based method in~\cite{Na:2014LteethMorph} is reliable, it produces poor results when applied to images obtained in an unrefined environment. On the other hand, it is well known that supervised learning methods can give excellent results for a variety of images, but require sufficient amount of training data for stable performance, and that the labeling process of training data takes a lot of time and effort.

The main applications of individual tooth segmentation are reconstruction of 3D tooth models, postmortem identification of deceased persons, and dental healthcare. In particular, the 3D teeth model reconstruction was developed based on individual tooth segmentation in CT images~\cite{Yuan:2020:teethParanomic,Naumovich:2015:teethCT3D}. However, in a recent study~\cite{WU:2016}, a 3D teeth model reconstruction method using individual tooth boundaries in a single teeth image was proposed.

In this paper, we segment individual tooth regions using the deep neural network and active contour model. First, we obtain the pseudo edge-region using a deep neural network. When preparing data for training the networks, manually select regions on the tooth boundary among edge-regions acquired by geometric attraction-driven flow (GADF). After that, active contour model is applied to segment regions with initial contours obtained from the pseudo edge-region. Finally, by identifying tooth and non-tooth regions, only the tooth region is obtained as a result.

The remainder of this paper is organized as follows. In Section~\ref{Sec:er_teeth}, we will discuss geometric attraction-driven flow (GADF), edge-regions, and problems of edge-regions obtained from teeth images. In Section~\ref{Sec:PM}, the proposed algorithm is described, and the experimental results are presented in Section~\ref{Sec:result}. We will conclude this paper in Section~\ref{Sec:Conclusion}. 

% Sec:Background
\section{GADF, edge-regions and segmentations}
\label{Sec:er_teeth}
In this section, we briefly review the GADF and edge-region in~\cite{Hahn:2006,Hahn:2010:GADF}, which play key roles in segmenting individual tooth. Then we will show that the edge-regions obtained by GADF are incomplete due to the problematic features of the teeth image.

% Subsec:GADF
\subsection{GADF}
\label{Subsec:GADF}
Let $I\colon\Omega\subset\mathbf{R}^2\rightarrow[0,\,1]$ be a given smooth gray image. The image intensity changes rapidly on the boundary of objects in the image. Thus, a point $x\in\Omega$ is defined as an edge point if
\begin{align*}
    u_x''(0)=0\cm %label{Def:edge}
\end{align*}
where
\begin{align*}
    u_x(s) = I\left( x + s\frac{\nabla{I(x)}}{|\nabla{I(x)}|} \right)\pd
\end{align*}
In \cite{Hahn:2010:GADF}, the GADF is defined as
\begin{align}
    F_a(x) = \mbox{sgn}(\ell(x))\frac{\nabla I(x)}{\left|\nabla{I(x)}\right|},\quad \forall{x}\in\Omega\cm  \label{Def:gadf}
\end{align}
where $\mbox{sgn}$ is the sign function and 
\begin{align*}
    \ell(x) &= \int^{\epsilon}_{0} {u'_x(s)}\,ds - \int^{0}_{-\epsilon} {u'_x(s)}\,ds\quad\mbox{for a small}~\epsilon > 0\pd
\end{align*}
By the definition, $F_a(x)$ points along the line $x + s\frac{\nabla{I(x)}}{|\nabla{I(x)}|}$ towards the edge point. The GADF can be naturally extended to color images; see~\cite{Hahn:2006,Hahn:2010:GADF}. In this paper, we consider the GADF only for grayscale images. A grayscale image are obtained by averaging each channel of a given color image.

% Subsection: Edge-regions
\subsection{Edge-regions}
\label{Subsec:edge-regions}

The edge-region is roughly defined as the curve of thin regions containing most of object boundaries, regardless of the strength of edges. In~\cite{Hahn:2010:GADF}, $\ome$ is a region, called the candidate of edge-region, where $F_a$ faces each other, i.e. 
\begin{align*}
    \ome = \left\{ x\in\Omega \mid F_a(x^*) \cdot F_a(x) < 0 ~\mbox{and}~ x^*=x+F_a(x) \right\}\pd %\label{Def:pre_er}
\end{align*}
Since $F_a$ is defined using normalized gradient, it is independent of the strength of edges. Thus $\ome$ is a region that satisfies the rough definition of the edge-region. But in practice, $\ome$ is a candidate for edge-region, because it contains many regions that are not intersected with the boundaries of the object. Hence it is necessary to remove them as many as possible. In~\cite{Hahn:2006}, the removing is performed by analyzing image intensity and morphology of candidate for edge-regions.

In Figure~\ref{Fig:edge_regions}, we can see that $\ome$ is well formed only at the boundary of objects for the synthetic image, but there are a lot of regions not intersected to object boundaries in the practical images. In the last row, edge-regions of several images obtained by removing unnecessary regions from the candidate of edge-regions are presented. We will elaborate about these regions in Section~\ref{Subsec:light_reflection}.

% Figure: Weak edges in teeth image
\input{./fig1.tex}

% Subsection: Active Contour Model
\subsection{Active Contour Model}
\label{Subsec:active_contour}



The movement of the contour is performed by a force applied in the normal direction to the contour. Therefore, by defining the appropriate force, we can move the contour to reach the boundary of the object. This kind of methods are called geometric active contours methods \cite{Caselles:1997:GAC,Xu:2000:ParamGeoAC} and are widely used formulated as a level set method.

As an initial contour evolves forward to edges, these unnecessary parts hinder the movement of the contour. In fact, except for connected components of $\oma$ with closed shape, it can be easily removed or disregarded; the components with a small size or flat image intensities around them are easily removed \cite{Hahn:2006}. For the components that cannot form a closed shape, the evolving contour can intrude from the ends and disregard the component. The connected components with closed shape are mainly caused by a strong light reflection. They, like a barrier, block the movement of the contour and make it difficult to find the correct tooth boundary. As a result, presence of such light reflections is a major obstacle to individual tooth segmentation. The described contour evolution is shown in Figure~\ref{Fig:er_outside}.

% Figure: Edge regions outside the tooth boundaries
\input{./fig2.tex}

액티브 컨투어에 대한 설명

Under this setting, contour evolution using a level set formulation is proposed in \cite{Hahn:2010:GADF}:
\begin{align}
    \frac{\partial}{\partial{t}}\phi(x,\,t) &= \mu\kappa(\phi)\left|\nabla\phi\right| - \chi_{\oma}F_a\cdot\nabla\phi + \chi_{\Omega_b}F_b|\nabla\phi|\cm \label{Eq:gadf}\\
    \phi(x,\,0) &= \phi_0(x)\cm \nonumber
\end{align}
where $\mu$ is a constant, $\phi_0$ is the initial signed distance function (SDF), $\chi$ is a characteristic function of the set of subscription and $\oma$ is a region, called the candidate of edge-regions, where $F_a$ faces each other, i.e.,
\begin{align*}
    \Omega_a = \delta_{S}\left( \Omega_E \right)\cm %\label{Def:oma}
\end{align*}
where
\begin{align*}
    \Omega_E = \left\{ x\in\Omega \mid F_a(x^*) \cdot F_a(x) < 0 ~\mbox{and}~ x^*=x+F_a(x) \right\}\pd %\label{Def:pre_er}
\end{align*}
and $\delta_{S}(X)$ is a dilation of a set $X$ by a $3 \times 3$ square structuring element $S$ with origin at its center. Observe that the initial contour goes outward in $\Omega_b = \Omega\setminus\Omega_a$ by a balloon force $F_b$ and approaches the edge by $F_a$ once it reaches in $\Omega_a$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
MMMMMMMMMMMMMMMMMMOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% Subsection: Light reflections in the teeth image
\subsection{Light reflections in teeth images}
\label{Subsec:light_reflection}

There have been several studies to remove light reflections in a single image \cite{SpecRemoval:2018,SpecRemoval:2020,SpecRemoval:2016,SpecRemoval:2015}. In these works, an image was separated into a non-reflective image and a reflection map in the image domain. These methods are based on the intensity histogram or assumption of a dichromatic image model using color information of the reflective region. However, in the case of teeth images, the colors of the light reflection and the tooth surface are almost the same due to the characteristics of human teeth. For this reason, when these methods are actually applied, parts of the tooth surface is also removed along with the light reflection. 

Although there was an attempt to remove the light reflection in teeth images using a single layer perceptron \cite{LeeRemoval:2010}, there is a limitation that it cannot be applied to a wide range of images because the perceptron has an extremely simple structure and learning is processed with only one image.

The most problematic thing is that even if light reflection is removed from the teeth image, individual tooth cannot be segmented immediately. This is because there are a lot of unnecessary edges besides the light reflection. If each is simple, it does not interfere with the movement of the contour, but if they stick together forming a large bunch or enclosing a region, it hinders the movement of the contour and becomes an obstacle to detecting the boundary of the tooth. In addition, when light reflection appears on the tooth boundary, the edge collapses when the light reflection is removed, so that the boundary becomes undetectable. Therefore, we seek a way to directly obtain only the edge-region near the tooth boundary, regardless of stains, noise or light reflection of the image. For this, a supervised learning method with deep neural networks is considered.

% Section: Proposed Method
\section{Proposed Method}
\label{Sec:PM}
In this section, we describe the steps of the proposed individual tooth segmentation algorithm. It has the following four main steps and the whole process is shown in Figure~\ref{Fig:flowchart}:

\begin{itemize}
\setlength{\itemindent}{5mm}
    \item[STEP 1] Obtaining pseudo edge-regions from a neural network,
    \item[STEP 2] Refinement of the pseudo edge-region,
    \item[STEP 3] Segmentation using active contours with competing ballon forces,
    \item[STEP 4] Identification of tooth and non--tooth region.
\end{itemize}

% Figure: Algorithm flowchart
\input{./fig3.tex}
    
% Subsection: Obtaining pre-edge regions from a neural network
\subsection{Obtaining pseudo edge-region from a neural network}
\label{Subsec:pre_er}

As shown in Figure~\ref{Fig:flowchart}(a), we make labels for training data using GADF and manual selection; first, we manually select the connected components of $\Omega_E$ intersecting the tooth boundary, then the label $Y\colon\Omega\subset\mathbf{R}^2\rightarrow\{0,\,1\}$ is defined as a binary image
\begin{align*}
    Y(x) =
    \begin{cases}
        1 & x\in\oms\cm\\
        0 & \mbox{otherwise}\cm
    \end{cases}
\end{align*}
where $\oms$ is obtained by dilating the selected regions from $\ome$ using an $\eta\times\eta$ square structuring element with the origin at its center. In Figure~\ref{Fig:labeling}, the labeling process is presented.

We consider a neural network consisting of the part of ResNeSt--50 \cite{Zhang:2020:ResNeSt} before the global average pooling layer as the encoder part and a custom upscaling module for the decoder part. The network takes a 3 channel image $X\colon\Omega\rightarrow\mathbf{R}^3$ as an input and produces an image $\hat{Y}\colon\Omega\rightarrow(0,\,1)$ as an output and is trained by minimizing the binary cross entropy (BCE) loss function \cite{Zhang:2018:BCE} of $Y$ and $\hat{Y}$. The entire network structure is shown in Figure~\ref{Fig:network}.

% Figure: Labeling images
\begin{figure}[]
    \centering
    \begin{subfigure}[]{.4\textwidth}
        \centering
        \includegraphics[height=3.8cm]{./Figures/Fig4_img.png}
        \caption{A training image \cite{T023}}
        \label{Fig:4a}
    \end{subfigure}
    \begin{subfigure}[]{.4\textwidth}
        \centering
        \includegraphics[height=3.8cm]{./Figures/Fig4_er.png}
        \caption{$\ome$}
        \label{Fig:4b}
    \end{subfigure}\\
    \vspace{1mm}
    \begin{subfigure}[]{.4\textwidth}
        \centering
        \includegraphics[height=3.8cm]{./Figures/Fig4_seler.png}
        \caption{Selected regions}
        \label{Fig:4c}
    \end{subfigure}
    \begin{subfigure}[]{.4\textwidth}
        \centering
        \includegraphics[height=3.8cm]{./Figures/Fig4_label.png}
        \caption{Labeled image $Y$}
        \label{Fig:4d}
    \end{subfigure}
    \caption{ Labeling process described in Section~\ref{Subsec:pre_er}: (a) An image in the training dataset. (b) The region $\Omega_E$. (c) Manually selected regions. (d) The labeled image obtained from (c) by the dilation. }
    \label{Fig:labeling}
\end{figure}

The network output $\hat{Y}(x)$ is the probability that an edge-region caused by the tooth boundary exists at $x$. We call
\begin{align}
    \omcc = \left\{ x\in\Omega \mid \hat{Y}(x) > 0.5 \right\} \label{Def:omcc}
\end{align}
as a pseudo edge-region of $X$, and examples of pseudo edge-regions for teeth images are shown in Figure~\ref{Fig:pre_er}.

% Figure: Network structure
\input{./TeethSeg_network.tex}

% Figure: pre_er
\begin{figure}[]
    \centering
    % \begin{subfigure}{.025\textwidth}
    %     \centering
    %     \caption*{\rotatebox[origin=c]{90}{\hspace{-4mm} (a) Input images}}
    %     \caption*{\rotatebox[origin=c]{90}{\hspace{-4mm} \footnotesize{(b) Pre--edge region} $\omcc$}}
    % \end{subfigure}
    \begin{subfigure}[]{.26\textwidth}
        \centering
        \includegraphics[height=2.4cm]{./Figures/Fig10_img0.pdf}
        \includegraphics[height=2.4cm]{./Figures/Fig10_neter0.pdf}
    \end{subfigure}
    \begin{subfigure}[]{.36\textwidth}
        \centering
        \includegraphics[height=2.4cm]{./Figures/Fig10_img1.pdf}
        \includegraphics[height=2.4cm]{./Figures/Fig10_neter1.pdf}
    \end{subfigure}
    \begin{subfigure}[]{.3\textwidth}
        \centering
        \includegraphics[height=2.4cm]{./Figures/Fig10_img5.pdf}
        \includegraphics[height=2.4cm]{./Figures/Fig10_neter5.pdf}
    \end{subfigure}
    \caption{First row: Input images. Second row: obtained pseudo edge-region from the neural network. }
    \label{Fig:pre_er}
\end{figure}

% Subsection: Refinement of pre--edge region
\subsection{Refinement of pseudo edge-region}
\label{Subsec:refine}

내용이바뀜내용이바뀜내용이바뀜내용이바뀜내용이바뀜내용이바뀜내용이바뀜내용이바뀜내용이바뀜내용이바뀜내용이바뀜내용이바뀜내용이바뀜

The region $\omcc$ in Section~\eqref{Def:omcc} is not yet perfect enough for segmenting individual tooth. Since it contains small fragments and leakages, which mean breakage of the closed curve, a refining process is applied to $\omcc$ to form a thick closed curve surrounding the individual tooth. First, small fragments and holes compared to the size of the image domain $\Omega$ are removed, and then dilation and erosion are sequentially applied by an $\omega \times\omega$ square structuring element with origin at its center. Second, since we want $\omcc$ to consist of thick closed curves,  Thus, we can fill the leakages by extending the ends of the curves in $\omcc$. By applying the chin--coding \cite{Freeman:1961:Chaincoding,Jonker:1992:Morphological} to the skeleton \cite{Blum:1967} of $\omcc$, we can find the parametric curves representing $\omcc$, see Figure~\ref{Fig:ex_ends_b}.

For each end, the strategy for extension is to return if not reached; if the leakage is not filled after a certain length of extension, then return and start extension in the next direction. Three directions are considered sequentially:
\begin{itemize}
    \setlength{\itemindent}{1.5mm}
    \item [(D--1)] If $\ome$ exists at the breaking of $\omcc$ and direction of $\ome$ coincides with the representative curve of $\omcc$, then $\omcc$ is extended along $\ome$,

    \item [(D--2)] Following the quadratic curve which is the least square quadratic approximation of the representative curve,

    \item [(D--3)] Following the straight line which is the least square linear approximation of the representative curve.
\end{itemize}
We call the resulting extension as $\omc$ and finally, we define a region $\ER := \omc\cap\ome$ which plays role of edge region. Examples of $\omc$ and $\ER$ are shown in Figure~\ref{Fig:ex_ends}.

% Figure: skeleton
\begin{figure}[]
    \centering
    \begin{subfigure}[]{.22\textwidth}
        \centering
        \includegraphics[height=3.5cm]{./Figures/Fig8_img.png}
        \caption{}
        \label{Fig:ex_ends_a}
    \end{subfigure}
    \begin{subfigure}[]{.22\textwidth}
        \centering
        \includegraphics[height=3.5cm]{./Figures/Fig8_curve.pdf}
        \caption{}
        \label{Fig:ex_ends_b}
    \end{subfigure}
    \begin{subfigure}[]{.22\textwidth}
        \centering
        \includegraphics[height=3.5cm]{./Figures/Fig8_ext.png}
        \caption{}
        \label{Fig:ex_ends_d}
    \end{subfigure}
    \begin{subfigure}[]{.22\textwidth}
        \centering
        \includegraphics[height=3.5cm]{./Figures/Fig8_use_er.png}
        \caption{$\ER$}
        \label{Fig:ex_useer_d}
    \end{subfigure}
    \caption{The process of extension from the ends of curves. (b) The parametric curves with ends (blue dots) are presented in $\omcc$ of the teeth image (a). (c) The extended region $\omc$. (d) Among $\ome$, the region $\ER$ is displayed in red. }
    \label{Fig:ex_ends}
\end{figure}

% Subsection: Segmentation using active contours with competing ballon forces
\subsection{Segmentation using active contours}
\label{Subsec:SegLevelset}

In this section, we denote $\sdf(A)$ by a SDF which is negative on the set $A$ and constantly zero on $\partial A$. In addition, for a SDF $\phi$, $\opp$, $\opn$ and $\opo$ denote the sets $\left\{x\mid \phi > 0 \right\}$, $\left\{x\mid \phi < 0 \right\}$ and $\left\{x\mid \phi = 0 \right\}$, respectively.

The movement of the contour is performed by a force applied in the normal direction to the contour. Therefore, by defining the appropriate force, we can move the contour to reach the boundary of the object. This kind of methods are called geometric active contours methods \cite{Caselles:1997:GAC,Xu:2000:ParamGeoAC} and are widely used formulated as a level set method. In this paper, we segment each tooth region using multiple active contours formulated as multiple level sets. Let $\{\Omega_i\}_{i=1}^N$ be a collection of all connected component of $\Omega\setminus\omc$. As shown in Figure~\ref{Fig:ex_ends_d}, $\omi$ is included in an individual tooth region, gum or oral cavity. Thus, to find a curve enclosing an individual tooth, we take the curve on $\partial\omi$ and push it outward until it reaches the boundary of the tooth. For this, we propose a contour evolution with a level set formulation:
\begin{align}
    \frac{\partial}{\partial{t}}\phi_i(x,\,t) &= \mu\kappa(\phi_i)\ngphii + \left( \chi_{\Omega\setminus\ER}\fci +\chi_{\omc\setminus\ER}F_s \right) \ngphii-\chi_{\ER}F_a\cdot \gphi \cm \label{Eq:proposed}\\
    \phi_i(x,\,0) &= \phi_{i,\,0}(x)\cm \nonumber
\end{align}
where $\mu$ is a constant, $\kappa(\phi)_i$ is the curvature of $\phi_i$, and $\phi_{i,\,0}(x)=\sdf(\omi)$ for all $i=1\cm\ldots\cm N$. Here are three forces $F_a$, $F_s$ and $\fci$; $F_a$ is GADF defined in~\eqref{Def:gadf}, $F_s$ is the statistically reinstating force proposed in~\cite{Park:2014:SRM}. The force $F_s(x)$ examines intensity distributions of in and out regions of a given contour and decided as $1$ or $-1$ to push the contour so that $x$ belongs to a region with more similar intensity. The force $\fci$ is the competing balloon force defined as
\begin{align*}
    \fci(x,\,t) =
        -1 - \sum_{j\neq i}\min\left(\phi_j(x,\,t) - 1,\,0\right)\cm\quad\forall i=1,\,\ldots,\,N\cm
\end{align*}
which is designed to inflate the set $\opn$ until it meets $\Omega_{\phi_{j}}^-$ for any $j\neq i$ and then stop.

Suppose that an initial contour $\opo$ is evolving by \eqref{Eq:proposed}. Basically, $\opn$ is inflated by $\fci$ so that $\opo$ enters the interior of the region $\omc$. In $\omc$, we consider three cases of $\opo$ in order: inside $\ER$, outside $\ER$ a way from other contours, and outside $\ER$ facing other contours. If $\opo$ is in $\ER$, it follows $F_a$ to the edge . If not, $\opo$ evolves by $\fci + F_s$ and edge is determined by the value of $F_s$ since $\fci$ only can have a value in $[-1,\,0]$. In the case that there are neither $\ER$ nor edges detected by $F_s$, the contour $\opo$ continues to evolve only with $\fci$ going until it encounters some other contours and determines an edge by competing each other.

% Subsection: Teeth and non-teeth region classification
\subsection{Identification of tooth and non-tooth regions}
\label{Subsec:regClass}

As a final step, the identification of the segmented regions remains. Since our goal is to segment each individual tooth from the result in Section~\ref{Subsec:SegLevelset}, we need to identify tooth and non-tooth regions. In a human teeth image, tooth and non-tooth regions can be easily distinguished by shape and color. Teeth are relatively white and convex in shape, thus non-tooth regions can be easily removed. We can check the shape or color of a region by considering several aspects: inertia tensor, curvature on the boundaries, and point distribution in a color space. The region having the following features is identified as a non--teeth region in order.

어펜딕스 가져오자어펜딕스 가져오자어펜딕스 가져오자어펜딕스 가져오자어펜딕스 가져오자어펜딕스 가져오자

% Section: Experimental results
\section{Experimental results and numerical aspect}
\label{Sec:result}

\textbf{Common parameters.} In all experiments, the parameter $\mu$ in~\eqref{} is fixed at $\mu=1$. In Section~\ref{}, $\eta=\lfloor|\Omega| / 600 + 1/2\rfloor$ and in Section~\ref{}, $\omega=2\lfloor\theta + 1/2\rfloor + 1$, where $\theta$ is the average thickness of $\omcc$ measured by sampling random points in $\omcc$. Also in Section~\ref{Subsec:refine}, small fragments with a skeleton shorter than $\sqrt{m^2+n^2} / 10$ and holes with size less than $mn / 10000$ are removed for an $m\times n$ image.

\noindent\textbf{Numerical schemes.} Overall, the finite difference scheme is applied to all derivatives. For the contour evolution \eqref{Eq:proposed}, the explicit Euler method is used. While performing the contour evolution, the level set function is frequently reinitialized by the method in \cite{SUSSMAN:1994}. The skeleton of $\omcc$ \eqref{} is obtained by applying a skeletonization algorithm of \cite{Zhang:1984} to $\left\{x \mid |\gphi(x)| < \sqrt{2}/2\right\}$ with $\phi=\sdf(\omcc)$.

\noindent\textbf{Data augmentation.} To get more diverse training data, data augmentation is applied. In each epoch, images are resized with randomly sampled height in $[256,\, 512]$, and $256\times256$ patch or its horizontal flip is randomly cropped \cite{He:2015:ResNet,Krizhevsky:2012:ImageNet}. Furthermore, for each image, the augmentation in the following list is randomly applied with a probability of $0.5$ within the given ranges:
\begin{itemize}
    \item Gaussian smoothing with $\sigma\in[0.25,\,0.75]$,
    \item Adding Gaussian noise with $\sigma\in[0.005,\,0.015]$,
    \item Gamma correction with $\gamma\in[0.5,\,2]$,
\end{itemize}

\noindent\textbf{Training data.} The training dataset consists of $46$ images obtained from web searches using various search terms. All teeth images contain \cite{} light reflections on the surface of teeth, gums or other parts.

\noindent\textbf{Training.} The neural network is trained by minimizing the BCE loss function \cite{Zhang:2018:BCE} using the Adam optimizer \cite{Kingma:2017}. The exponential decay rates for the moment of Adam optimizer are set $(\beta_1,\,\beta_2)=(0.9,\,0.999)$ and the learning rate is $0.005$. Network is trained over $10{,}000$ epochs with $46$ iterations for each epoch, and the parameters after the last epoch are selected. 

\noindent\textbf{Results.} In Figure~\ref{Fig:results}, several teeth images with its segmentation results for existing and proposed methods are presented. As shown in the figure, the proposed method shows prominent results. Quantitative measurement is impossible since there is no ground truth, but compared to the results of the existing methods, it can be seen that the tooth regions are neatly segmented. In particular, only the tooth regions are segmented in the teeth images the lips and the face part exist.

% Figure: Edge region candidate and results
\begin{figure}[]
    \newcommand*{\wdth}{2.5}%
    \newcommand*{\twdth}{.16}%
    \centering
    \begin{subfigure}[]{\twdth \textwidth}
        \centering
        \includegraphics[width=\wdth cm]{./Figures/Fig10_img0.pdf}
        \includegraphics[width=\wdth cm]{./Figures/Fig10_img1.pdf}
        \includegraphics[width=\wdth cm]{./Figures/Fig10_img5.pdf}
        \includegraphics[width=\wdth cm]{./Figures/Fig10_img8.pdf}
        \includegraphics[width=\wdth cm]{./Figures/Fig10_img18.pdf}
        \includegraphics[width=\wdth cm]{./Figures/Fig10_img17.pdf}
        \caption{Input images}
    \end{subfigure}
    \begin{subfigure}[]{\twdth \textwidth}
        \centering
        \includegraphics[width=\wdth cm]{./Figures/lee2010_0.pdf}
        \includegraphics[width=\wdth cm]{./Figures/lee2010_1.pdf}
        \includegraphics[width=\wdth cm]{./Figures/lee2010_5.pdf}
        \includegraphics[width=\wdth cm]{./Figures/lee2010_8.pdf}
        \includegraphics[width=\wdth cm]{./Figures/lee2010_18.pdf}
        \includegraphics[width=\wdth cm]{./Figures/lee2010_17.pdf}
        \caption{MCWA \cite{LeeWater:2010}}
        \label{Fig:lee2010}
    \end{subfigure}
    \begin{subfigure}[]{\twdth \textwidth}
        \centering
        \includegraphics[width=\wdth cm]{./Figures/lee2010s_0.pdf}
        \includegraphics[width=\wdth cm]{./Figures/lee2010s_1.pdf}
        \includegraphics[width=\wdth cm]{./Figures/lee2010s_5.pdf}
        \includegraphics[width=\wdth cm]{./Figures/lee2010s_8.pdf}
        \includegraphics[width=\wdth cm]{./Figures/lee2010s_18.pdf}
        \includegraphics[width=\wdth cm]{./Figures/lee2010s_17.pdf}
        \caption{MCWA2 \cite{LeeSegRemoval:2010}}
        \label{Fig:lee2010_2}
    \end{subfigure}
    \begin{subfigure}[]{\twdth \textwidth}
        \centering
        \includegraphics[width=\wdth cm]{./Figures/na2014_0.pdf}
        \includegraphics[width=\wdth cm]{./Figures/na2014_1.pdf}
        \includegraphics[width=\wdth cm]{./Figures/na2014_5.pdf}
        \includegraphics[width=\wdth cm]{./Figures/na2014_8.pdf}
        \includegraphics[width=\wdth cm]{./Figures/na2014_18.pdf}
        \includegraphics[width=\wdth cm]{./Figures/na2014_17.pdf}
        \caption{MWA \cite{Na:2014LteethMorph}}
        \label{Fig:na2014}
    \end{subfigure}
    \begin{subfigure}[]{\twdth \textwidth}
        \centering
        \includegraphics[width=\wdth cm]{./Figures/Fig10_res0.pdf}
        \includegraphics[width=\wdth cm]{./Figures/Fig10_res1.pdf}
        \includegraphics[width=\wdth cm]{./Figures/Fig10_res5.pdf}
        \includegraphics[width=\wdth cm]{./Figures/Fig10_res8.pdf}
        \includegraphics[width=\wdth cm]{./Figures/Fig10_res18.pdf}
        \includegraphics[width=\wdth cm]{./Figures/Fig10_res17.pdf}
        \caption{Our algorithm}
        \label{Fig:result}
    \end{subfigure}
    \caption{ Segmented results of several methods for input images \cite{T000,T008,T005,T018,T017}. }
    \label{Fig:results}
\end{figure}

% Section: Conclusion
\section{Conclusion}
\label{Sec:Conclusion}

In this paper, we proposed a method for individual tooth segmentation in a human teeth image. Including the strong light reflection, there are several obstacles that hinder the segmentation process. We solved these problem by acquiring pseudo edge-region using a deep neural network with supervised learning. In the labeling process, model-based methods were used to reduce time consumption and cost. In addition, we proposed contour evolution to inflating the initial contour using different forces depending on the situation 

to find the boundary of the tooth from te refined pseudo edge-regions + identification of tooth and non-tooth region. 

Among the existing methods, model-based methods show insufficient performance. Although the supervised learning method using Mask R--CNN has similar performance to ours, it is difficult to label the data for training. This work is significant in that it proposed an algorithm that can easily prepare training data while performing well through a combination of model-based methods and a supervised learning method. It is noted that the combination of the two methods produced a synergistic effect; model-based methods streamline the labeling process for training deep neural networks and the networks simplify the problem by inferring pseudo edge-regions. 

One of the most important application of individual tooth segmentation is the 3D teeth model reconstruction. That this study will be of great help in reconstructing a more sophisticated 3D teeth model from a 2D teeth image.

% Section: Acknowledgement
% \section*{Acknowledgement}

%% Appendix
\appendix
\section{List of features of non-tooth region}
\label{App:list_nonteeth}

The methods in the list below is applied sequentially for identification of tooth and non-tooth regions. For a region, let $c$ be the center of mass and $\mathcal{I}$ the inertia tensor about $c$. Then the inertia tensor has two eigenvalues $\Lambda$ and $\lambda$ ($\Lambda \le \lambda$). Let $v$ be an normalized eigenvector corresponding to the $\lambda$. Let the image $I$ be embedded into the CIELAB color space~\cite{} and denoted by $I_{LAB}(x)=[L(x),\,A(x),\,B(x)]$, and let $x^*\in\Omega$ be a point such that
\begin{align*}
    x^* = \argmax A(x)\pd
\end{align*}

\begin{itemize}
    \item [(F--1)] If the center of mass $c$ is outside the region, a region identified as a non-tooth region.

    \item [(F--2)] If the ratio $\Lambda / \lambda$ is larger than the average of the ratio for all regions and $|v\cdot e_1| \le \cos(\pi/4)$ for $e_1 = (1,\,0)$, the region identified as a non-tooth region.
    
    \item [(F--3)] Count the number of points with positive or negative curvature on the boundary of region. If there are more points of negative curvature than points of positive curvature, the region is identified as a non-tooth region
    
    \item [(F--4)] For each vertical line passing through the region, values of $I_{LAB}$ on the points where the line passes are clustered together $I_{LAB}(x^*)$ by the $k$--means clurstering algorithm.
\end{itemize}

%% References
\bibliographystyle{siam}
\bibliography{bibliography}

\end{document}
