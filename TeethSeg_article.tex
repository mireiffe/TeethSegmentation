\documentclass[10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{geometry} % to change the page dimensions
\geometry{a4paper}
\usepackage{authblk}

%% Packages
\usepackage{graphicx, subcaption}
\usepackage{amsmath,amssymb,amsthm,amsfonts}
\usepackage{bm}
\usepackage{algorithm, algorithmic}
\usepackage{multirow}
\usepackage{bbm}
\usepackage{hyperref,url}
\usepackage{kotex}
\usepackage[labelformat=simple]{subcaption}

\usepackage{tikz}
\usetikzlibrary{shapes.geometric, arrows, positioning, calc}
\usetikzlibrary{backgrounds}
\usetikzlibrary{arrows.meta}

\tikzstyle{title} = [rectangle, minimum width=3cm, minimum height=1cm, text centered, draw=black, text width=3cm, fill=white!100]
\tikzstyle{startstop} = [rectangle, rounded corners, minimum width=3cm, minimum height=1cm,text centered, draw=black, fill=red!30]
\tikzstyle{io} = [trapezium, trapezium left angle=70, trapezium right angle=110, minimum width=3cm, minimum height=1cm, text width=1.3cm, text centered, draw=black, fill=blue!30]
\tikzstyle{process} = [rectangle, minimum width=3cm, text width=3cm, minimum height=1cm, text centered, draw=black, fill=orange!30]
\tikzstyle{decision} = [diamond, minimum width=3cm, minimum height=1cm, text centered, draw=black, fill=green!30]
\tikzstyle{arrow} = [thick,->,>=stealth]

\captionsetup[figure]{labelsep=period}
% \renewcommand{\thefigure}{\Roman{figure}}
% \captionsetup[subfigure]{labelformat=parens} % default is 'parens'
% \renewcommand{\thesubfigure}{\thefigure.\alph{subfigure}.}
\renewcommand\thesubfigure{(\alph{subfigure})}

%% Theorems
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}

\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{example}[theorem]{Example}

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}

%% Equations
\numberwithin{equation}{section}

%% Algorithms
\renewcommand\algorithmicdo{}
\renewcommand\algorithmicthen{}
\renewcommand\algorithmicendfor{\textbf{end}}

%% Macros
\def\chfun{\mathbbm{1}}
\def\skel{\mathcal{S}}
\def\calc{\mathcal{C}}
\def\sko{\hat{\mathcal{S}}}
\def\ske{\mathcal{S}^8}
\def\endske{E\left(\mathcal{S}^8\right)}
\def\endomc{E\left(\Omega_c\right)}


\def\gphi{\nabla\phi}
\def\ngphi{\left|\nabla\phi\right|}
\def\ngphii{\left|\nabla\phi_i\right|}
\def\fci{F_{c,\,i}}
\def\fcj{F_{c,\,j}}
\def\cm{\, ,}
\def\pd{\, .}

\def\omi{\Omega_i}
\def\oma{\Omega_a}
\def\ome{\Omega_E}
\def\oms{\Omega_S}
\def\omc{\overline{\Omega}_P}
\def\omcc{\Omega_P}
\def\ER{\Omega_{Er}}

\def\opp{\Omega_{\phi_i}^+}
\def\opn{\Omega_{\phi_i}^-}
% \def\opo{\Omega_{\phi}^0}
\def\opo{C_{\phi_i}}

\def\sdf{\mbox{SDF}}

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
% \def\tOmega{\tilde{\Omega}}
% \def\tGamma{\tilde{\Gamma}}
% \def\tV{\tilde{V}}
% \def\W{\mathbb{W}}
% \def\tu{\tilde{u}}
% \def\bu{\bar{u}}
% \def\hu{\hat{u}}
% \def\bl{\bar{\lambda}}
% \def\p{\mathbf{p}}
% \def\P{\mathbf{P}}
% \def\intO{\int_{\Omega}}
% \def\intOs{\int_{\Omega_s}}
% \def\m{\mathbf{m}}
% \def\n{\mathbf{n}}
% \def\blambda{\bm{\lambda}}

% \def\tE{\tilde{E}}
% \def\N{\mathcal{N}}

% \def\div{\mathrm{div}}
% \def\proj{\mathrm{proj}}
% \def\prox{\mathrm{prox}}
% \def\ran{\mathrm{ran}\,}
% \def\ed{\mathrm{ed}}
% \def\supp{\mathrm{supp}\,}
% \def\TOL{\mathrm{TOL}}
% \DeclareMathOperator*{\argmin}{\arg\min}

% Text Color and Strike
\usepackage[normalem]{ulem}
\usepackage{color}
\newcommand{\red}[1]{{\color{red}{#1}}}
\newcommand{\blue}[1]{{\color{blue}{#1}}}

\title{ Individual Tooth Segmentation in Human Teeth Images Using Pseudo Edge-Regions Obtained by Deep Neural Networks }
\author{Seongeun Kim and Chang-Ock Lee}
\affil{Department of Mathematical Sciences, KAIST, Daejeon 34141, Korea}
\date{ }

\begin{document}
\maketitle

\begin{abstract}
In human teeth images taken outside the oral cavity with a general digital camera, it is difficult to segment individual tooth due to common obstacles such as weak edges, intensity inhomogeneities and strong light reflections. In this work, we propose a method for segmenting individual tooth in human teeth images. The key of the method is to obtain pseudo edge-regions using deep neural networks. \textit{After additional steps to connect the pseudo edge-regions}, we apply an active contour model to segment the individual tooth. We also present a strategy using existing model-based methods for labeling the data required for neural network training.
\end{abstract}

{\small \textbf{Key words}
Tooth segmentation, Neural network, Geometric attraction--driven flow, Edge-region, Light reflection}

{\small \textbf{AMS subject classifications}
94A08, 68T07}

%% Main text starts ---------------------------------------------------------------------------------------------------
% Section: Introduction
\section{Introduction}
\label{Sec:Introduction}

Image segmentation is one of major topics in the field of computer vision. The main goal of image segmentation is to segment objects in an image according to a specific purpose and many outstanding methodologies have been developed. The active contour model is one of the popular methods for the image segmentation. It makes the contour surrounding an object move to the boundary of the object with the designed force~\cite{Kass:1988:Snakes}; gradient vector flows~\cite{Xu:1997:GVF}, geodesic active contours~\cite{Caselles:1997:GAC} and balloon forces~\cite{Cohen:1991:Balloon} are well-known models with different forces. There are also variational models that uses statistical information of intensities in an image~\cite{Park:2014:SRM,Zhu:1996:RegCompet}. In \cite{Chan:2001:chanvese}, unlike the previous methods using edge maps, a region-based active contour method was proposed.

Segmentation of individual tooth in human teeth images has been mainly performed on computed tomography (CT) or X-ray images~\cite{Yuan:2020:teethParanomic,Naumovich:2015:teethCT3D,Said:2006:teethxray,Shah:2006:teethautoseg}. Teeth are easily segmented in these CT or X-ray images since the intensity of the teeth region is much stronger than the gums or tissues. However, segmenting individual tooth in a teeth image taken outside the oral cavity with a general digital camera is a more difficult problem. In the teeth images, not only weak edges and light reflections appear, but also colors and illuminance are inhomogeneous due to plaque and oral structure, which are major obstacles to segmentation of individual tooth. Several attempts have been made to segment individual tooth in teeth images. In~\cite{Na:2014LteethMorph} the watershed algorithm~\cite{Vincent:1991:watershed} with color information was proposed. In recent studies \cite{Kim:2020,Pham:2020,Zhu:2020:teethMaskrcnn}, segmentations using deep learning methods based on Mask R--CNN \cite{He:2018:MRCNN} were proposed. In~\cite{WU:2016}, a supervised learning method BEL~\cite{Dollar:2006:BEL} was used to obtain the individual tooth boundaries. 

Although the model-based method in~\cite{Na:2014LteethMorph} is reliable, it produces poor results when applied to images obtained in an unrefined environment. On the other hand, it is well known that supervised learning methods can give excellent results for a variety of images, but require sufficient amount of training data for stable performance, and that the labeling process of training data takes a lot of time and effort.

The main applications of individual tooth segmentation are reconstruction of 3D tooth models, postmortem identification of deceased persons, and dental healthcare. In particular, the 3D teeth model reconstruction was developed based on individual tooth segmentation in CT images~\cite{Yuan:2020:teethParanomic,Naumovich:2015:teethCT3D}. However, in a recent study~\cite{WU:2016}, a 3D teeth model reconstruction method using individual tooth boundaries in a single teeth image was proposed.

In this paper, we segment individual tooth regions by obtaining pre-edge region using the supervised learning method. In the supervised learning process, data labeling process is assisted by model-based methods to avoid spending time and cost.

The remainder of this paper is organized as follows. In Section~\ref{Sec:er_teeth}, we will discuss geometric attraction-driven flow (GADF), edge-regions, and problems of edge-regions obtained from teeth images. In Section~\ref{Sec:PM}, the proposed algorithm is described, and the experimental results are presented in Section~\ref{Sec:result}. We will conclude this paper in Section~\ref{Sec:Conclusion}. 

% Sec:Background
\section{Geometric Attraction-Driven Flow, edge-regions and segmentations}
\label{Sec:er_teeth}
In this section, we briefly review the geometric attraction-driven flow (GADF) and edge-region in~\cite{Hahn:2006, Hahn:2010:GADF}, which play key roles in segmenting individual tooth. Then we will show that the edge-regions obtained by GADF are incomplete due to the problematic features of the teeth image.

% Subsec:GADF
\subsection{GADF}
\label{Subsec:GADF}
Let $I\colon\Omega\subset\mathbf{R}^2\rightarrow[0,\,1]$ be a given smooth gray image. The image intensity changes rapidly on the boundary of objects in the image. Thus, a point $x\in\Omega$ is defined as an edge point if
\begin{align*}
    u_x''(0)=0\cm %label{Def:edge}
\end{align*}
where
\begin{align*}
    u_x(s) = I\left( x + s\frac{\nabla{I(x)}}{|\nabla{I(x)}|} \right)\pd
\end{align*}
In \cite{Hahn:2010:GADF}, the GADF is defined as
\begin{align*}
    F_a(x) = \mbox{sgn}(\ell(x))\frac{\nabla I(x)}{\left|\nabla{I(x)}\right|},\quad \forall{x}\in\Omega\cm  %\label{Def:gadf}
\end{align*}
where $\mbox{sgn}$ is the sign function and 
\begin{align*}
    \ell(x) &= \int^{\epsilon}_{0} {u'_x(s)}\,ds - \int^{0}_{-\epsilon} {u'_x(s)}\,ds\quad\mbox{for a small}~\epsilon > 0\pd
\end{align*}
By the definition, $F_a(x)$ points along the line $x + s\frac{\nabla{I(x)}}{|\nabla{I(x)}|}$ towards the edge point. The GADF can be naturally extended to color images; see~\cite{Hahn:2006,Hahn:2010:GADF}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
MMMMMMMMMMMMMMMMMMOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Under this setting, contour evolution using a level set formulation is proposed in \cite{Hahn:2010:GADF}:
\begin{align}
    \frac{\partial}{\partial{t}}\phi(x,\,t) &= \mu\kappa(\phi)\left|\nabla\phi\right| - \chi_{\oma}F_a\cdot\nabla\phi + \chi_{\Omega_b}F_b|\nabla\phi|\cm \label{Eq:gadf}\\
    \phi(x,\,0) &= \phi_0(x)\cm \nonumber
\end{align}
where $\mu$ is a constant, $\phi_0$ is the initial signed distance function (SDF), $\chi$ is a characteristic function of the set of subscription and $\oma$ is a region, called the candidate of edge-regions, where $F_a$ faces each other, i.e.,
\begin{align*}
    \Omega_a = \delta_{S}\left( \Omega_E \right)\cm %\label{Def:oma}
\end{align*}
where
\begin{align*}
    \Omega_E = \left\{ x\in\Omega \mid F_a(x^*) \cdot F_a(x) < 0 ~\mbox{and}~ x^*=x+F_a(x) \right\}\pd %\label{Def:pre_er}
\end{align*}
and $\delta_{S}(X)$ is a dilation of a set $X$ by a $3 \times 3$ square structuring element $S$ with origin at its center. Observe that the initial contour goes outward in $\Omega_b = \Omega\setminus\Omega_a$ by a balloon force $F_b$ and approaches the edge by $F_a$ once it reaches in $\Omega_a$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
MMMMMMMMMMMMMMMMMMOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Subsection: Edges outside the tooth boundaries
\subsection{Edges-regions}
\label{Subsec:er_outside}

The edge-region is roughly defined as the AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA of thin regions containing most of object boundaries, regardless of the strength of edges. In practice, as shown in Figure~\ref{Fig:1d}, $\oma$ is a candidate for the edge-region, because $\ome$ contains many regions that are not intersected with the boundaries of the objects. Hence it is necessary to remove them as many as possible.

% Figure: Weak edges in teeth image
\input{./fig1.tex}

As an initial contour evolves forward to edges, these unnecessary parts hinder the movement of the contour. In fact, except for connected components of $\oma$ with closed shape, it can be easily removed or disregarded; the components have small size or flat image intensities around them are easily removed \cite{Hahn:2006}. For the components that cannot form a closed shape, the evolving contour can intrude from the ends and disregard the component. The connected components with closed shape are mainly caused by a strong light reflection. They block the movement of the contour and make it difficult to find the correct tooth boundary like a barrier. As a result, presence of such light reflections is a major obstacle to individual tooth segmentation. The described contour evolution is shown in Figure~\ref{Fig:er_outside}.

% Figure: Edge regions outside the tooth boundaries
\input{./fig2.tex}


% Subsection: Avoidance of light reflections in the teeth image
\subsection{Avoiding light reflections in teeth images}
\label{Subsec:avoidance}

There are previous studies to remove light reflections in a single image \cite{SpecRemoval:2018,SpecRemoval:2020,SpecRemoval:2016,SpecRemoval:2015}. In these, an image was separated into non--reflective image and reflection map on the image domain. These methods are based on the intensity histogram or assuming a dichromatic image model which uses color information of the reflective region. But in the case of teeth images, the colors of the light reflection and the tooth surface are almost the same due to the characteristics of human teeth. For this reason, when these methods are actually applied, a part of the tooth surface is also removed with the light reflection. 

There has been an attempt to remove the light reflection in teeth images using the single layer perceptron \cite{LeeRemoval:2010}, but there is a limitation that it cannot be applied to a wide range of image because learning is processed using only one image as well as the perceptron has an extremely simple structure.

The most important thing is that even if light reflection is removed from the teeth image, individual tooth can not be segmented immediately. There are a lot of unnecessary edges appear other than due to the light reflection. Each can be breakable since it does not have a closed shape, but if they stick together forming a large bunch or a closed shape, it becomes an obstacle to detect boundary. In addition, if light reflection appears on the tooth boundary, the edge collapses and the boundary becomes undetectable when the light reflection is removed. Therefore, we seek a way to directly obtain only the edge region near the tooth boundary, regardless of stains, noise or light reflection of the image. For this, a supervised learning method with deep neural networks is considered.

% Section: Proposed Method
\section{Proposed Method}
\label{Sec:PM}
In this section, we describe the steps of the proposed individual tooth segmentation algorithm. It have the following four main steps and the whole process is shown in Figure~\ref{Fig:flowchart}:

\begin{itemize}
    \item[STEP 1] Obtaining pre--edge regions from a neural network,
    \item[STEP 2] Refinement of the pre--edge region,
    \item[STEP 3] Segmentation using active contours with competing ballon forces,
    \item[STEP 4] Identification of tooth and non--tooth region.
\end{itemize}

% Figure: Algorithm flowchart
\input{./fig3.tex}
    
% Subsection: Obtaining pre-edge regions from a neural network
\subsection{Obtaining pre--edge regions from a neural network}
\label{Subsec:pre_er}

As shown in Figure~\ref{Fig:flowchart}(a), we make labels for training data using GADF and manual selection; first, we manually select the connected components of $\Omega_E$ overlapping the tooth boundary, and the label $Y\colon\Omega\subset\mathbf{R}^2\rightarrow\{0,\,1\}$ is defined as a binary image
\begin{align*}
    Y(x) =
    \begin{cases}
        1 & x\in\oms\\
        0 & \mbox{otherwise}
    \end{cases}\cm
\end{align*}
where $\oms$ is obtained by dilation of the selected region from $\ome$ using a structuring element which is an $\eta\times\eta$ matrix with the origin at its center. For training, the part of ResNeSt--50 \cite{Zhang:2020} before the global average pooling layer is used as the encoder part, and a custom upscale module is designed for the decoder part. The network takes a 3 channel image $X\colon\Omega\rightarrow\mathbf{R}^3$ as an input and produces a 1 channel image $\hat{Y}\colon\Omega\rightarrow(0,\,1)$ as an output and is trained by minimizing the binary cross entropy (BCE) loss function \cite{Zhang:2018:BCE} of $Y$ and $\hat{Y}$. In Figure~\ref{Fig:labeling}, the labeling process is presented and the entire network structure is shown in the Figure~\ref{Fig:network}.

% Figure: Labeling images
\begin{figure}[]
    \centering
    \begin{subfigure}[]{.4\textwidth}
        \centering
        \includegraphics[height=3.8cm]{./Figures/Fig4_img.png}
        \caption{A training image \cite{T023}}
        \label{Fig:4a}
    \end{subfigure}
    \begin{subfigure}[]{.4\textwidth}
        \centering
        \includegraphics[height=3.8cm]{./Figures/Fig4_er.png}
        \caption{$\ome$}
        \label{Fig:4b}
    \end{subfigure}\\
    \vspace{1mm}
    \begin{subfigure}[]{.4\textwidth}
        \centering
        \includegraphics[height=3.8cm]{./Figures/Fig4_seler.png}
        \caption{Selected region}
        \label{Fig:4c}
    \end{subfigure}
    \begin{subfigure}[]{.4\textwidth}
        \centering
        \includegraphics[height=3.8cm]{./Figures/Fig4_label.png}
        \caption{Labeled image}
        \label{Fig:4d}
    \end{subfigure}
    \caption{ Labeling process described in Section~\ref{Subsec:pre_er}. (a) An image in the training dataset. (b) The region $\Omega_E$. (c) Manually selected regions. (d) The labeled image obtained from (c) by the dilation. }
    \label{Fig:labeling}
\end{figure}

The network output $\hat{Y}(x)$ is the probability that an edge region caused by tooth boundary exists at $x$. We call
\begin{align*}
    \omcc = \left\{ x\in\Omega \mid \hat{Y}(x) > 0.5 \right\}
\end{align*}
as a pre--edge region of $X$, and pre--edge regions for some teeth images are shown in Figure~\ref{Fig:pre_er}. One notable point is that although the label contains many unnecessary regions, most of $\omcc$ are correctly located on the tooth boundary.

% Figure: Network structure
\begin{figure}[]
    \centering
    \input{./TeethSeg_network.tex}
    \caption{The structure of neural network used in this paper. Overall, each bold arrow represents a layer and types of the layers are listed on the right--bottom legend in order to arrow colors. Each layer is followed by a batch normalization (BN) and an activation function, with only two exceptions; the global average poolings (GAP) and fully connected layers in (b) having thin lines width. The type of the activation function is represented by the shape of arrow heads, and it is also listed in the legend. In the legend, there are some notations; $/$ and $+$ mean stride and padding of the layer with the followind number, respectively. The bilinear upscaling is applied with scale factor $2$. When $c \neq m$ in (b), a modification occurs in RNS--$m$ as same as downsampling layers in the ResNet \cite{He:2015:ResNet,He:2019:ResNetTrick}; MOD1 is added after the first layer and the dashed identity connection changes to MOD2 in the legend. }
    \label{Fig:network}
\end{figure}

% Figure: pre_er
\begin{figure}[]
    \centering
    % \begin{subfigure}{.025\textwidth}
    %     \centering
    %     \caption*{\rotatebox[origin=c]{90}{\hspace{-4mm} (a) Input images}}
    %     \caption*{\rotatebox[origin=c]{90}{\hspace{-4mm} \footnotesize{(b) Pre--edge region} $\omcc$}}
    % \end{subfigure}
    \begin{subfigure}[]{.26\textwidth}
        \centering
        \includegraphics[height=2.4cm]{./Figures/Fig10_img0.pdf}
        \includegraphics[height=2.4cm]{./Figures/Fig10_neter0.pdf}
    \end{subfigure}
    \begin{subfigure}[]{.36\textwidth}
        \centering
        \includegraphics[height=2.4cm]{./Figures/Fig10_img1.pdf}
        \includegraphics[height=2.4cm]{./Figures/Fig10_neter1.pdf}
    \end{subfigure}
    \begin{subfigure}[]{.3\textwidth}
        \centering
        \includegraphics[height=2.4cm]{./Figures/Fig10_img5.pdf}
        \includegraphics[height=2.4cm]{./Figures/Fig10_neter5.pdf}
    \end{subfigure}
    \caption{(First row) Input images and (Second row) obtained pre--edge regions. }
    \label{Fig:pre_er}
\end{figure}

% Subsection: Refinement of pre--edge region
\subsection{Refinement of pre--edge region}
\label{Subsec:refine}

The region $\omcc$ obtained in Section~\ref{Subsec:pre_er} is not yet perfect. As it contains small fragments and leakages, we apply a refinement process to $\omcc$ to form closed individual tooth area. First, small fragments and holes are removed compared to the size of the image domain $\Omega$, and then dilation and erosion are applied in order by the structuring element of $\omega \times\omega$ matrix with origin at its center. Second, since we want $\omcc$ to consist of thick closed curves, leakage means breaking of the closed curve. Thus, we can fill the leakages by extending the ends of the curves in $\omcc$. By applying the chin--coding \cite{Freeman:1961:Chaincoding,Jonker:1992:Morphological} to the skeleton \cite{Blum:1967} of $\omcc$, we can find the parametric curves representing $\omcc$, see Figure~\ref{Fig:ex_ends_b}.

For each end, the strategy for extension is to return if not reached; if the leakage is not filled after a certain length of extension, then return and start extension in the next direction. Three directions are considered sequentially:
\begin{itemize}
    \item [(D--1)] If $\ome$ exists at the breaking of $\omcc$ and direction of $\ome$ coincides with the representative curve of $\omcc$, then $\omcc$ is extended along $\ome$,

    \item [(D--2)] Following the quadratic curve which is the least square quadratic approximation of the representative curve,

    \item [(D--3)] Following the straight line which is the least square linear approximation of the representative curve.
\end{itemize}
We call the resulting extension as $\omc$ and finally, we define a region $\ER := \omc\cap\ome$ which plays role of edge region. Examples of $\omc$ and $\ER$ are shown in Figure~\ref{Fig:ex_ends}.

% Figure: skeleton
\begin{figure}[]
    \centering
    \begin{subfigure}[]{.22\textwidth}
        \centering
        \includegraphics[height=3.5cm]{./Figures/Fig8_img.png}
        \caption{}
        \label{Fig:ex_ends_a}
    \end{subfigure}
    \begin{subfigure}[]{.22\textwidth}
        \centering
        \includegraphics[height=3.5cm]{./Figures/Fig8_curve.pdf}
        \caption{}
        \label{Fig:ex_ends_b}
    \end{subfigure}
    \begin{subfigure}[]{.22\textwidth}
        \centering
        \includegraphics[height=3.5cm]{./Figures/Fig8_ext.png}
        \caption{}
        \label{Fig:ex_ends_d}
    \end{subfigure}
    \begin{subfigure}[]{.22\textwidth}
        \centering
        \includegraphics[height=3.5cm]{./Figures/Fig8_use_er.png}
        \caption{}
        \label{Fig:ex_useer_d}
    \end{subfigure}
    \caption{The process of extension from the ends. (b) The parametric curves with ends (blue dots) are presented on $\omcc$ of the teeth image (a). (c) The extended region $\omc$. (d) Among $\ome$, the region $\ER$ is highlighted by with red color. }
    \label{Fig:ex_ends}
\end{figure}

% Subsection: Segmentation using active contours with competing ballon forces
\subsection{Segmentation using active contours with competing ballon forces}
\label{Subsec:SegLevelset}

In this section, we denote $\sdf(A)$ by a SDF which is negative on the set $A$ and constantly zero on $\partial A$. In addition, for a SDF $\phi$, $\opp$, $\opn$ and $\opo$ denote the sets $\left\{x\mid \phi > 0 \right\}$, $\left\{x\mid \phi < 0 \right\}$ and $\left\{x\mid \phi = 0 \right\}$, respectively.

The movement of the active contour is only affected by the force applied in the normal direction of the contour. Therefore, by defining the force, we can move the active contour to achieve our goal. This kind of methods are called geometric active contours \cite{Caselles:1997:GAC,Xu:2000:ParamGeoAC} and widely used by formulated as a level set method. In this paper, we segment each tooth region using multiple active contours formulated by multiple level sets. Let $\{\Omega_i\}_{i=1}^N$ be a connected component of a set $\Omega\setminus\omc$. As shown in Figure~\ref{Fig:ex_ends_d}, some $\omi$ is a subset of each tooth region obtained by subtracting $\omc$ from the entire tooth region. Thus, to find tooth regions, we push each $\partial\omi$ inside $\omc$ and stop when it arrives an edge point. For this, we propose a contour evolution using a level set formulation:
\begin{align}
    \frac{\partial}{\partial{t}}\phi_i(x,\,t) &= \mu\kappa(\phi_i)\ngphii + \left( \chi_{\Omega\setminus\ER}\fci +\chi_{\omc\setminus\ER}F_s \right) \ngphii-\chi_{\ER}F_a\cdot \gphi \cm \label{Eq:proposed}\\
    \phi_i(x,\,0) &= \phi_{i,\,0}(x)\cm \nonumber
\end{align}
where $\mu$ is a constant and $\phi_{i,\,0}(x)=\sdf(\omi)$ for all $i=1\cm\cdots\cm N$. There are three forces $F_a$, $F_s$ and $\fci$; $F_a$ is GADF defined in \eqref{Def:gadf}, $F_s$ is the statistically reinstating force proposed in \cite{Park:2014:SRM}. The force $F_s(x)$ examine intensity distributions of in and out regions of a given contour and decided as $1$ or $-1$ to push the contour so that $x$ belongs to a region with more similar intensity. The force $\fci$ is the competing balloon force defined as
\begin{align*}
    \fci(x,\,t) =
        -1 - \sum_{j\neq i}\min\left(\phi_j(x,\,t) - 1,\,0\right)\cm\quad\forall i=1,\,\cdots,\,N\cm
\end{align*}
which is designed to inflate the set $\opn$ until it meet $\Omega_{\phi_{j}}^-$ for any $j\neq i$, and then stop.

Suppose that an initial contour $\opo$ is evolving by \eqref{Eq:proposed}. Basically, $\opn$ is inflated by $\fci$ and so $\opo$ goes into the surrounding region $\omc$. In $\omcc$, we can consider three cases in order; $\opo$ is in $\ER$, outside $\ER$ and far from the other contour, or outside $\ER$ and faces to other contours. If $\opo$ is in $\ER$, it goes to edge following $F_a$. If not, $\opo$ evolves by $\fci + F_s$ and edge is determined by the value of $F_s$ since $\fci$ only can have a value in $[-1,\,0]$.
In the case of there are neither $\ER$ nor detected edge by $F_s$, the contour $\opo$ evolves only following $\fci$ and so keeps going until it faces some other contours and determines edge by competing each other.

% Subsection: Teeth and non-teeth region classification
\subsection{Identification of tooth and non-tooth regions}
\label{Subsec:regClass}

As a final step, the identification of the segmented regions remains. Since our goal is to segment each individual tooth from the result in Section~\ref{Subsec:SegLevelset}, we identify tooth and a non-tooth regions. In a human teeth image, tooth and non--tooth regions can be distinguished by shape and color. Teeth are relatively white and have convex shape, thus contrasting regions can be removed. We can check the shape or color of a region by considering several aspects; inertia tensor about the center of mass, curvature on the boundaries or point distribution in a color space. The region having features in the list of Appendix~\ref{App:list_nonteeth} is identified as a non--teeth region in order.

% Section: Experimental results
\section{Experimental results and numerical aspect}
\label{Sec:result}

\textbf{Common parameters.} For the all experiments, parameters are fixed as $\mu=1$ and $\eta=\lfloor|\Omega| / 600 + 1/2\rfloor$. In Section~\ref{Subsec:refine}, $\omega=2\lfloor\theta + 1/2\rfloor + 1$ where $\theta$ is average thickness of $\omcc$ measured by sampling random points in $\omcc$. In the Section~\ref{Subsec:refine}, small fragments having skeleton shorter than $\sqrt{m^2+n^2} / 10$ and holes with size $< mn / 10000$ are removed where $m$ and $n$ are height and width of the image, respectively.

\noindent\textbf{Numerical schemes.} Overall, finite difference scheme is applied to all differentiations. For the contour evolution in \eqref{Eq:proposed}, the explicit Euler method is used. While doing the contour evolution, the level set function is frequently reinitialized by the method in \cite{SUSSMAN:1994}. The skeleton of  $\omcc$ in Section~\ref{Subsec:refine} is obtained by applying a skeletonization algorithm of \cite{Zhang:1984} to $\left\{x \mid \ngphi(x) < \sqrt{2}/2\right\}$ where $\phi=\sdf(\omcc)$.

\noindent\textbf{Data augmentation.} To get more diverse training data, data augmentations are applied. In each epoch, images are resized with randomly sampled height in $[256,\, 512]$, and $256\times256$ patch or its horizontal flip is randomly cropped \cite{He:2015:ResNet,Krizhevsky:2012:ImageNet}. Furthermore, for each image and each augmentation in the following list, it is randomly decided that the augmentation is applied or not with a probability of $0.5$:
\begin{itemize}
    \item Gaussian smoothing with $\sigma_1\in[0.25,\,0.75]$,
    \item Adding Gaussian noise with $\sigma_2\in[0.005,\,0.015]$,
    \item Gamma correction with $\gamma\in[0.5,\,2]$,
\end{itemize}
each parameter was randomly determined within the given ranges.

\noindent\textbf{Training data.} The training dataset is composed as $46$ images obtained from web search using various search words. All teeth images contains light reflections on the surface of teeth, gums or other parts.

\noindent\textbf{Training.} The neural network is trained by minimizing the BCE loss function \cite{Zhang:2018:BCE} using the Adam optimizer \cite{Kingma:2017}. Exponential decay rates for moment of Adam optimizer are set as $(\beta_1,\,\beta_2)=(0.9,\,0.999)$ and the learning rate is $0.005$. Network is trained over $10000$ epochs with $46$ iterations for each epoch, and the parameters after the last epoch are selected. In Figure~\ref{Fig:results}, several teeth images and its segmentation results for existing and proposed methods. As shown in the figure, the proposed method shows prominent performance. Quantitative measurement is not possible since there is no ground truths, but compared to the results of the existing methods, it can be seen that the tooth regions are neatly segmented. In particular, only the tooth regions are segmented in the teeth images in which the lips and the face part exist.

% Figure: Edge region candidate and results
\begin{figure}[]
    \newcommand*{\wdth}{2.5}%
    \newcommand*{\twdth}{.16}%
    \centering
    \begin{subfigure}[]{\twdth \textwidth}
        \centering
        \includegraphics[width=\wdth cm]{./Figures/Fig10_img0.pdf}
        \includegraphics[width=\wdth cm]{./Figures/Fig10_img1.pdf}
        \includegraphics[width=\wdth cm]{./Figures/Fig10_img5.pdf}
        \includegraphics[width=\wdth cm]{./Figures/Fig10_img8.pdf}
        \includegraphics[width=\wdth cm]{./Figures/Fig10_img18.pdf}
        \includegraphics[width=\wdth cm]{./Figures/Fig10_img17.pdf}
        \caption{Input images}
    \end{subfigure}
    \begin{subfigure}[]{\twdth \textwidth}
        \centering
        \includegraphics[width=\wdth cm]{./Figures/lee2010_0.pdf}
        \includegraphics[width=\wdth cm]{./Figures/lee2010_1.pdf}
        \includegraphics[width=\wdth cm]{./Figures/lee2010_5.pdf}
        \includegraphics[width=\wdth cm]{./Figures/lee2010_8.pdf}
        \includegraphics[width=\wdth cm]{./Figures/lee2010_18.pdf}
        \includegraphics[width=\wdth cm]{./Figures/lee2010_17.pdf}
        \caption{MCWA \cite{LeeWater:2010}}
        \label{Fig:lee2010}
    \end{subfigure}
    \begin{subfigure}[]{\twdth \textwidth}
        \centering
        \includegraphics[width=\wdth cm]{./Figures/lee2010s_0.pdf}
        \includegraphics[width=\wdth cm]{./Figures/lee2010s_1.pdf}
        \includegraphics[width=\wdth cm]{./Figures/lee2010s_5.pdf}
        \includegraphics[width=\wdth cm]{./Figures/lee2010s_8.pdf}
        \includegraphics[width=\wdth cm]{./Figures/lee2010s_18.pdf}
        \includegraphics[width=\wdth cm]{./Figures/lee2010s_17.pdf}
        \caption{MCWA2 \cite{LeeSegRemoval:2010}}
        \label{Fig:lee2010_2}
    \end{subfigure}
    \begin{subfigure}[]{\twdth \textwidth}
        \centering
        \includegraphics[width=\wdth cm]{./Figures/na2014_0.pdf}
        \includegraphics[width=\wdth cm]{./Figures/na2014_1.pdf}
        \includegraphics[width=\wdth cm]{./Figures/na2014_5.pdf}
        \includegraphics[width=\wdth cm]{./Figures/na2014_8.pdf}
        \includegraphics[width=\wdth cm]{./Figures/na2014_18.pdf}
        \includegraphics[width=\wdth cm]{./Figures/na2014_17.pdf}
        \caption{MWA \cite{Na:2014LteethMorph}}
        \label{Fig:na2014}
    \end{subfigure}
    \begin{subfigure}[]{\twdth \textwidth}
        \centering
        \includegraphics[width=\wdth cm]{./Figures/Fig10_res0.pdf}
        \includegraphics[width=\wdth cm]{./Figures/Fig10_res1.pdf}
        \includegraphics[width=\wdth cm]{./Figures/Fig10_res5.pdf}
        \includegraphics[width=\wdth cm]{./Figures/Fig10_res8.pdf}
        \includegraphics[width=\wdth cm]{./Figures/Fig10_res18.pdf}
        \includegraphics[width=\wdth cm]{./Figures/Fig10_res17.pdf}
        \caption{ours}
        \label{Fig:result}
    \end{subfigure}
    \caption{(a) Input images \cite{T000,T008,T005,T018,T017} and segmented results. }
    \label{Fig:results}
\end{figure}

% Section: Conclusion
\section{Conclusion}
\label{Sec:Conclusion}

In this paper, we proposed a method for individual tooth segmentation in a human teeth image. Including the strong light reflection, there are several obstacles that hinder the segmentation process. We solved these problem by acquiring pre--edge region using deep supervised learning method. In the labeling process, model--based supporting was devised in order to reduce the time consuming and costs. In addition, we proposed a contour evolution which determines edges using different forces depending on the situation while inflating the initial contour. 

Among the existing methods, the model-based method shows insufficient performance. Although the supervised learning method using Mask R--CNN has excellent performance, it is difficult to construct the training data. This work is significant in that it proposed an algorithm that can easily prepare training data while having good performance through a combination of a model--based method and a supervised learning method. It was observed that the combination of the two methods made a synergistic effect; model--based methods streamline the labeling process for training neural networks and the networks simplify the problem by inferring pre--edge regions. 

One of the most important application of individual tooth segmentation is the 3D teeth model reconstruction. It is hoped that this study will be of great help in reconstructing 3D teeth model from a 2D teeth image. In addition, obtaining pre--edge region learning can be widely applied to difficult image segmentation problems. Therefore, we hope that this strategy can be a breakthrough for other image segmentation problems that are not yet easy to solve.

% Section: Acknowledgement
% \section*{Acknowledgement}

%% Appendix
\appendix
\section{List of features of non-tooth region}
\label{App:list_nonteeth}

The list below is applied sequentially, that is, the features of the next number are examined against regions not removed from the previous number. For a region, $c$ is the center of mass and $\mathcal{I}$ is the inertia tensor about the $c$. Furthermore, $\Lambda$ and $\lambda$ are maximal and minimal eigenvalues of $\mathcal{I}$, respectively, and $v$ is an normalized eigenvector corresponding to the $\lambda$. Let the image $I$ be embedded into the CIELAB color space and by denoted $I_{LAB}(x)=[L(x),\,A(x),\,B(x)]$, and let $x^*\in\Omega$ be a point such that
\begin{align*}
    x^* = \argmax A(x)\pd
\end{align*}

\begin{itemize}
    \item [(F--1)] The center of mass $c$ is outside the region,

    \item [(F--2)] The ratio $\Lambda / \lambda$ is large than the average of the ratio for all regions and $|v\cdot e_1| < \cos(\pi/9)$ where $e_1$ is unit vector $(1,\,0)$,
    
    \item [(F--3)] When counting the number of points with positive or negative curvature on the edge, there are more points of negative curvature than points of positive curvature,
    
    \item [(F--4)] For each vertical line passing through the region, values of $I_{LAB}$ on the points where the line passes are clustered together $I_{LAB}(x^*)$ by the $k$--means clurstering algorithm.
\end{itemize}

%% References
\bibliographystyle{siam}
\bibliography{bibliography}

\end{document}
