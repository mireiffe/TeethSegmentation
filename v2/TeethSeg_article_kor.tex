\documentclass[10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{geometry} % to change the page dimensions
\geometry{a4paper}
\usepackage{authblk}

%% Packages
\usepackage{graphicx,subfig}
\usepackage{amsmath,amssymb,amsthm,amsfonts}
\usepackage{bm}
\usepackage{algorithm, algorithmic}
\usepackage{multirow}

\usepackage{kotex}

%% Theorems
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}

\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{example}[theorem]{Example}

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}

%% Equations
\numberwithin{equation}{section}

%% Algorithms
\renewcommand\algorithmicdo{}
\renewcommand\algorithmicthen{}
\renewcommand\algorithmicendfor{\textbf{end}}

%% Macros
% \def\tOmega{\tilde{\Omega}}
% \def\tGamma{\tilde{\Gamma}}
% \def\tV{\tilde{V}}
% \def\W{\mathbb{W}}
% \def\tu{\tilde{u}}
% \def\bu{\bar{u}}
% \def\hu{\hat{u}}
% \def\bl{\bar{\lambda}}
% \def\p{\mathbf{p}}
% \def\P{\mathbf{P}}
% \def\intO{\int_{\Omega}}
% \def\intOs{\int_{\Omega_s}}
% \def\m{\mathbf{m}}
% \def\n{\mathbf{n}}
% \def\blambda{\bm{\lambda}}

% \def\tE{\tilde{E}}
% \def\N{\mathcal{N}}

% \def\div{\mathrm{div}}
% \def\proj{\mathrm{proj}}
% \def\prox{\mathrm{prox}}
% \def\ran{\mathrm{ran}\,}
% \def\ed{\mathrm{ed}}
% \def\supp{\mathrm{supp}\,}
% \def\TOL{\mathrm{TOL}}
% \DeclareMathOperator*{\argmin}{\arg\min}

% Text Color and Strike
\usepackage[normalem]{ulem}
\usepackage{color}
\newcommand{\red}[1]{{\color{red}{#1}}}
\newcommand{\blue}[1]{{\color{blue}{#1}}}

\title{Individual Tooth Segmentation in Two Dimensional Human Teeth Image}
\author{Seongeun Kim}
\affil{Department of Mathematical Sciences, KAIST, Daejeon 34141, Korea}
\date{}

\begin{document}
\maketitle

\begin{abstract}
In this paper, we propose a segmentation method.\end{abstract}

{\small \textbf{Key words}
Image Processing, Neural Networks, Data Processing}

{\small \textbf{AMS subject classifications}
94A08, 68T07}

%% Main text starts ---------------------------------------------------------------------------------------------------
% Section: Introduction
\section{Introduction}
\label{Sec:Introduction}
3차원 치아 복원의 필요성\\
- 전문적인 복원과정의 소모성\\
CT로부터 치아복원 연구들\\
파라노마 이미지로부터 복원 연구들\\
외부에서 촬영된 2차원 치아경계로부터 복원 가능 논문 \cite{wu2016teeth}\\
연구의 목적

% \section{Related works and common features of teeth image}
% \label{Sec:RW}
% In this section, we briefly mention how previous researches has been conducted, and how common features of teeth images can be obstacles in the segmentation process.
% Relatively first, attempts are made to segment the tooth image into binary regions, teeth and non-tooth regions.

\section{Background}
\label{Sec:BG}
In this section, we briefly review GADF and edge region, which plays important role for segmenting individual tooth. We will derive how to obtain edge regions by concentrating the problematic features of teeth image.

\subsection{Geometric Attraction-Driven Flow}
\label{Subsec:GADF}
Assume there is a smooth gray image $I:\Omega\subset\mathbf{R}^2\rightarrow[0,\,1]$. The image intensity changes rapidly on the boundary of two objects in the image. 이미지상의 한 물체에서 다른 물체로 움직임는 경계에서, 이미지 인텐시티는 급격하게 변화하게 된다. 따라서 우리는 $I$의 세기가 주변에 비해 급격히 변화하는 지점, 즉
\begin{align*}
    u_x(s) = I\left( x + s\frac{\nabla{I(x)}}{|\nabla{I(x)}|} \right),
\end{align*}
에 대하여 $\left.u_x''(s)\right|_{s=0}=0$이 되는 $x\in\Omega$를 이미지의 edge로 정의한다. geometric attraction-driven flow(GADF)는 액티브 컨투어 모델의 하나로 제안되었는데, \cite{HAHN201056} 흑백 이미지 $I$에 대하여 다음과 같이 정의된다:
\begin{align}
    F_a = \mbox{sgn}(\ell(x))\frac{I(x)}{\left|\nabla{I(x)}\right|},\quad \forall{x}\in\Omega,  \label{Def:gadf_def}
\end{align}
where the $\mbox{sgn}$ is a general sign function and 
\begin{align*}
    \ell(x) &= \int^{\epsilon}_{0} {u'_x(s)} ds - \int^{0}_{-\epsilon} {u'_x(s)} ds\quad\mbox{for a small}~\epsilon > 0.
\end{align*}

$F_a$는 정의에 따라서 $u_x''(s)=0$이 되는 지점, 즉 edge를 바라보게 된다. \cite{HAHN201056}에서는 $F_a$가 서로 마주보는 영역, 즉
\begin{align}
    \Omega_a = \delta_S\left( \Omega_E \right), \label{Def:edge_region}
\end{align}
where $\delta_S$ is a dilation function
\begin{align*}
    \Omega_E = \left\{ x\in\Omega \mid F_a(x^*) \cdot F_a(x) < 0 ~\mbox{and}~ x^*=x+F_a(x) \right\},
\end{align*}
을 edge region이라 정의하였으며, $\Omega_a$에서는 경계에 정밀하게 가까워지고 $\Omega \setminus \Omega_a$에서는 팽창하는 level set formulation을 이용한 contour evolution을 제안하였다:
\begin{align}
    \frac{\partial}{\partial{t}}\phi(x,\,t) &= \alpha\kappa\left|\nabla\phi\right| - g_aF_a\cdot\nabla\phi + (1 - g_a)F_b|\nabla\phi|, \label{Eq:gadf}\\
    \phi(x,\,0) &= \phi_0(x). \nonumber
\end{align}
where $\alpha$ is a constant, $\kappa$ is the curvature of level set functions $\phi$ and $g_a$ is a characteristic function on the set $\Omega_a$. 

GADF는 color 이미지로도 자연스럽게 확장 가능하다. 3차원 이미지 $I:\Omega\subset\mathbf{R}^2\rightarrow[0,\,1]^3$을 생각할 때, 우리는 nonlinear structure tensor $\mathbf{M}$ from a nonlinear diffusion
\begin{align*}
    \frac{\partial \mathbf{M}(x,\,t)}{\partial t}&=\nabla\cdot\left( h\left( \sum_{i,\,j=1}^2 \left|\nabla M_{ij}(x,\,t)\right|^2  \right) \nabla\mathbf{M}(x,\,t) \right),\\
    \mathbf{M}(x,\,0) &= \sum_{k=1}^3 {\nabla I_k(x)I_k(x)^T},
\end{align*}
에 대해서 생각할 수 있는데, 이 diffused tensor $\mathbf{M}$은 이미지의 local feature를 보존하고 있다 \cite{brox2006nonlinear,rousson2003active,hahn2009nonlinear,Weickert2004CoherenceEnhancingDF}. 우리는 $\mathbf{M}$의 maximum eigenvalue에 대응되는 eigenvector $v_\Lambda$를 이미지의 그래디언트로 생각할 수 있으며, 그렇다면 컬러 이미지에서의 GADF계산은 트랙터블하다.

% Subsection: Weak Edge Detection
\subsection{Weak edge detection}
\label{Subsec:WED}
이미지의 edge에서의 인텐시티 변화량이 주변보다 작아서 검출하기 어려운 경우, 우리는 weak edge라고 부른다. 회색조 이미지 $I$에 대하여,
\begin{align*}
    \nabla{|\nabla{I}|} \parallel \mathcal{H}_x(I)\nabla{I}  
\end{align*}
라는 건 계산을통해 쉽게 알 수 있다. 이미지의 인텐시티 변화량이 주변과 많은 차이를 가지게 되면, hessian 행렬 때문에 $\nabla|\nabla{I}|$의 방향이 $\nabla{I}$와는 달라지게 된다. 즉, 이 weak edge주변에서는 단순히 컬러정보의 변화만으로 정확한 edge를 결정하기는 어렵다는 걸 알 수 있다. 그러나, \eqref{Def:gadf_def}에서 볼 수 있듯이 GADF의 경우 $\nabla{I}$와 $-\nabla{I}$ 둘 중 하나의 방향을 가지도록 정의되었기 때문에 컬러의 변화량의 크기에 않고 weak edge까지도 모두 포함하는 edge region을 구성할 수 있다. 내츄럴 사람 치아 이미지에서는 이런 weak edge가 보편적으로 나타난다. 특히 치아와 잇몸사이의 경계와, 색과 밝기가 비슷한 두 치아의 경계 등에서 나타나는데, 이런 경계들은 일반적인 방법으로는 검출하기 어렵다. Figure~\ref{Fig:weak_edges}에는 치아영상에서 보이는 weak edge와, 각각 다른 방법으로 검출한 경계들이 나타나있다.

% Figure: Weak edges of teeth image
\begin{figure}[]
    \centering
    \subfloat[][]{ \includegraphics[height=4.8cm]{./Figures/seg_eta.png} }
    \subfloat[][]{ \includegraphics[height=4.8cm]{./Figures/seg_comp.png} }
    \caption{(a) Human teeth image with weak edges}
    \label{Fig:weak_edges}
\end{figure}

% Subsection: Edge regions outside the tooth boundaries
\subsection{Edge regions outside the tooth boundaries}
\label{Subsec:ERTB}

내츄럴 치아 이미지에서는 물체 표면의 inhomogeneities 나 이미지 자체의 noise등으로 인해 치아의 경계 외에서도 edge가 잡다하게 나타나기도 한다. 이러한 edge들 때문에 GADF로부터 계산되는 edge region는 치아경계 외에도 크고 작은 connected region들을 아주 많이 포함하고 있다. 이런 불필요한 영역들을 그대로 둔 상태에서는 contour가 원하는 경계의 근처에 가도록 할 수 없기때문에, 반드시 제거해줘야 한다. 이런 영역들은, 생성 원인에 따라 크게 3가지로 나누어 생각할 수 있는데:
\begin{itemize}
    \item [(1)] Noise나 작은 얼룩에 의해 생기는 edge regions,
    \item [(2)] 상대적으로 크고 희미한 얼룩에 의해 생기는 edge regions,
    \item [(3)] 강한 specular reflection에 의해 생기는 edge regions.
\end{itemize} 
이다. (1)은 크기가 작으며 그 주위에서 영상의 컬러가 상대적으로 flat한 영역들이다. 치아 경계에서 나타나는 edge region들은 큰 영역을 형성하며, 주위에서 컬러의 변화가 클 것이라고 가정할 수 있기 때문에, (1)로 인해 생기는 영역들은 우선적으로 제거할 수 있다. (2) 물체 표면의 얼룩들 중에는 상대적으로 큰 edge region을 만들어내는 경우가 있다. 이런 영역들은 크기와 컬러정보만으로는 치아 경계에서의 edge regions와 구분하는 게 쉽지않다. 하지만, 얼룩의  전체가 뚜렷하지 않고 일부 희미한 부분이 존재할 경우, 그 부분에서의 edge region의 말단이 노출되게 된다. 초기 contour가 evolution해나갈때, 말단을 만난다면 GADF를 따라서 shrink해나가게 되므로 이런 희미한 얼룩의 일부에서 생겨나는 edge region은 쉽게 무력화시킬 수 있다. 반면에, (3)과 같이 치아의 표면에 강하게 나타나는 빛반사로부터 생기는 edge region들은 크기가 크고, 닫힌 형태를 가지고 있는 경우가 많다. 이로인해 새로운 closed region을 만들어내는데, 말단이 노출되어있지 않기 때문에 contour evolution을 하더라도 무력화시킬 수 없고, 치아 경계로부터 생기는 edge region들과의 형태정보와 컬러정보를 이용한 구분은 사실상 불가능하다. 이런 영역들은 베리어같이 contour의 길을 막아서 올바른 치아 경계를 찾지 못하모록 만드며, 결과적으로 치아 분할을 어렵게 만드는 주 요인이다. 이 내용들은 Figure~\ref{Fig:edge_regions_outside}에서 확인할 수 있다.

% Figure: Edge regions outside the tooth boundaries
\begin{figure}[]
    \centering
    \subfloat[][]{ \includegraphics[height=4.8cm]{./Figures/seg_eta.png} }
    \subfloat[][]{ \includegraphics[height=4.8cm]{./Figures/seg_comp.png} }
    \caption{(a) Human teeth image with weak edges}
    \label{Fig:edge_regions_outside}
\end{figure}

% Subsection: Avoidance of Right reflection in the teeth image
\subsection{Avoidance of Right reflection in the teeth image}
\label{Subsec:SRR}

기존의 연구들 중에, single 일반적인 이미지의 이런 정반사 영역을 제거하려는 시도들이 있었다 \cite{SpecRemoval:2006,SpecRemoval:2015,SpecRemoval:2016,SpecRemoval:2018}. 이런 기법들은 기본적으로 빛반사가 존재하는 이미지를, 빛반사가 없는 이미지와 빛반사로 분리하려 노력하고 있는데, 이를 위해 image intensity histogram이나 dichromatic image model등을 가정하고 있다. 이런 방식은 기본적으로 빛반사 영역의 색정보를 이용하여 빛반사를 분리하려하는 것인데, 치아 이미지의 경우 치아의 특성상 빛반사와 치아표면의 색이 거의 비슷하다. 이 때문에, 실제로 기존의 방법들을 적용해보면 빛반사와 함깨 치아 표면의 일부도 제거되는 일이 발생하게 된다. 치아 이미지를 대상으로 빛반사를 제거하려는 시도도 있었으나 \cite{LeeRemoval:2010}, 이는 한 장의 이미지에서 우리가 대상으로 삼는 것처럼 다양한 범위의 이미지에 적용하기에는 제한적이다. 무엇보다, 치아 이미지로부터 빛반사를 제거하더라도 이미지의 상태나, 치아 표면의 강한 얼룩들 때문에 불필요한 edge region들이 많이 생성된다면 개별치아를 분할하는 건 여전히 여려운 일이라는 걸 알 수 있다. 따라서 우리는 치아 이미지로부터 경계주변에 위치한 edge region만을 직접적으로 얻어내려고 하였으며, 이를 위해 neural network를 supervised learning하는 방법을 생각하였다.

% Section: Proposed Method
\section{Proposed Method}
\label{Sec:PM}
이 섹션에서, 우리는 제안된 개별 치아 분할이 어떤 단계들을 거쳐서 이루어지는지 설명하겠다.
그것은 다음과 같은 네개의 주요 단계를 거쳐서 이루어지며, 전체 과정은 Figure~\ref{Fig:algorithm_flowchart}에 나타나 있습니다.: 
(1) 개별 치아의 경계를 학습하기 위한 데이터 레이블링, 
(2) 뉴럴 네트워크로부터 edge region candidate 얻어냄, 
(3) 경계역역후보 다듬기 그리고 
(4) 서로 경쟁하는 active contour 방법을 이용한 segmentation.

% Figure: Algorithm flowchart
\begin{figure}[]
    \centering
    \subfloat[][]{ \includegraphics[height=4.8cm]{./Figures/seg_eta.png} }
    \subfloat[][]{ \includegraphics[height=4.8cm]{./Figures/seg_comp.png} }
    \caption{Algorithm flowchart for the proposed method}
    \label{Fig:algorithm_flowchart}
\end{figure}

\subsection{이미지의 정보를 잘 반영하면서, 손이 덜 가는 레이블링 과정}
\label{Subsec:Labeling}

111

%% References
\bibliographystyle{siam} 
\bibliography{bibliography}

\end{document}
