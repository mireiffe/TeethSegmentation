\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{Kass:1988:Snakes}
\citation{Xu:1997:GVF}
\citation{Caselles:1997:GAC}
\citation{Chan:2001:chanvese}
\citation{Yuan:2020:teethParanomic}
\citation{Naumovich:2015:teethCT3D}
\citation{Said:2006:teethxray}
\citation{Shah:2006:teethautoseg}
\citation{Na:2014LteethMorph}
\citation{Vincent:1991:watershed}
\citation{WU:2016}
\citation{Dollar:2006:BEL}
\citation{Kim:2020}
\citation{Pham:2020}
\citation{Zhu:2020:teethMaskrcnn}
\citation{He:2018:MRCNN}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\newlabel{Sec:Introduction}{{1}{1}{Introduction}{section.1}{}}
\citation{Pretty:2001:forensic}
\citation{Yuan:2020:teethParanomic}
\citation{Naumovich:2015:teethCT3D}
\citation{WU:2016}
\citation{Shah:2006:teethautoseg}
\citation{Pretty:2001:forensic}
\citation{Hahn:2006}
\citation{Hahn:2010:GADF}
\citation{Hahn:2010:GADF}
\@writefile{toc}{\contentsline {section}{\numberline {2}GADF, edge-regions, and segmentation}{2}{section.2}\protected@file@percent }
\newlabel{Sec:er_teeth}{{2}{2}{GADF, edge-regions, and segmentation}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}GADF}{2}{subsection.2.1}\protected@file@percent }
\newlabel{Subsec:GADF}{{2.1}{2}{GADF}{subsection.2.1}{}}
\newlabel{Def:gadf}{{2.1}{2}{GADF}{equation.2.1}{}}
\citation{Hahn:2006}
\citation{Hahn:2010:GADF}
\citation{Hahn:2010:GADF}
\citation{Hahn:2006}
\citation{Hahn:2010:GADF}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Edge-regions}{3}{subsection.2.2}\protected@file@percent }
\newlabel{Subsec:edge-regions}{{2.2}{3}{Edge-regions}{subsection.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Active contour model}{3}{subsection.2.3}\protected@file@percent }
\newlabel{Subsec:active_contour}{{2.3}{3}{Active contour model}{subsection.2.3}{}}
\newlabel{Eq:ac_gadf}{{2.2}{3}{Active contour model}{equation.2.2}{}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{Fig:edge_regions_4}{{1(c)}{4}{\footnotesize Edge-region $\oma $\relax }{figure.caption.1}{}}
\newlabel{sub@Fig:edge_regions_4}{{(c)}{4}{\footnotesize Edge-region $\oma $\relax }{figure.caption.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces  (a) A synthetic image, a teeth image without light reflection, and a teeth image with light reflection are shown from top to bottom. (b) Edge-region candidates $\Omega _E$ of the left images. (c) Edge-region $\Omega _a$ is refined using component size and image intensity. \relax }}{4}{figure.caption.1}\protected@file@percent }
\newlabel{Fig:edge_regions}{{1}{4}{(a) A synthetic image, a teeth image without light reflection, and a teeth image with light reflection are shown from top to bottom. (b) Edge-region candidates $\ome $ of the left images. (c) Edge-region $\oma $ is refined using component size and image intensity. \relax }{figure.caption.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces From left to right, multiple contours evolved by\nobreakspace  {}\textup  {\hbox {\mathsurround \z@ \normalfont (\ignorespaces \ref  {Eq:ac_gadf}\unskip \@@italiccorr )}} are shown over time. The evolution steps are presented from the initial-state to the steady-state. There are three active contours with different colors. Observe that if a contour meets an edge-region, it digs into the edge-region along GADF, and if the edge-region encloses regions, the contour stops at the boundary of these regions. However, a contour faces an end of region of non-closed shape, the contour invades the region and eventually encroaches. \relax }}{4}{figure.caption.2}\protected@file@percent }
\newlabel{Fig:evolution}{{2}{4}{From left to right, multiple contours evolved by~\eqref {Eq:ac_gadf} are shown over time. The evolution steps are presented from the initial-state to the steady-state. There are three active contours with different colors. Observe that if a contour meets an edge-region, it digs into the edge-region along GADF, and if the edge-region encloses regions, the contour stops at the boundary of these regions. However, a contour faces an end of region of non-closed shape, the contour invades the region and eventually encroaches. \relax }{figure.caption.2}{}}
\citation{SpecRemoval:2018}
\citation{SpecRemoval:2020}
\citation{SpecRemoval:2016}
\citation{SpecRemoval:2015}
\citation{Shafer:1985:colorsep}
\citation{LeeRemoval:2010}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Light reflections in teeth images}{5}{subsection.2.4}\protected@file@percent }
\newlabel{Subsec:light_reflection}{{2.4}{5}{Light reflections in teeth images}{subsection.2.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Proposed Method}{5}{section.3}\protected@file@percent }
\newlabel{Sec:PM}{{3}{5}{Proposed Method}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Obtaining pseudo edge-region from a neural network}{5}{subsection.3.1}\protected@file@percent }
\newlabel{Subsec:pseudo_er}{{3.1}{5}{Obtaining pseudo edge-region from a neural network}{subsection.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Algorithm flowchart: (a) Data labeling and training process. (b) Segmentation process. \relax }}{6}{figure.caption.3}\protected@file@percent }
\newlabel{Fig:flowchart}{{3}{6}{Algorithm flowchart: (a) Data labeling and training process. (b) Segmentation process. \relax }{figure.caption.3}{}}
\citation{Zhang:2020:ResNeSt}
\citation{Zhang:2018:BCE}
\citation{T023}
\citation{T023}
\newlabel{Fig:4a}{{4(a)}{7}{A training image \cite {T023}\relax }{figure.caption.4}{}}
\newlabel{sub@Fig:4a}{{(a)}{7}{A training image \cite {T023}\relax }{figure.caption.4}{}}
\newlabel{Fig:4b}{{4(b)}{7}{Edge-region candidate~$\ome $\relax }{figure.caption.4}{}}
\newlabel{sub@Fig:4b}{{(b)}{7}{Edge-region candidate~$\ome $\relax }{figure.caption.4}{}}
\newlabel{Fig:4c}{{4(c)}{7}{Selected regions~$\oms $\relax }{figure.caption.4}{}}
\newlabel{sub@Fig:4c}{{(c)}{7}{Selected regions~$\oms $\relax }{figure.caption.4}{}}
\newlabel{Fig:4d}{{4(d)}{7}{Labeled image~$Y$\relax }{figure.caption.4}{}}
\newlabel{sub@Fig:4d}{{(d)}{7}{Labeled image~$Y$\relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces  Labeling process described in Section\nobreakspace  {}\ref  {Subsec:pseudo_er}: (a)\nobreakspace  {}An image in the training dataset. (b)\nobreakspace  {}Region $\Omega _E$. (c)\nobreakspace  {}Manually selected regions. (d)\nobreakspace  {}The labeled image obtained from\nobreakspace  {}(c) by the dilation. \relax }}{7}{figure.caption.4}\protected@file@percent }
\newlabel{Fig:labeling}{{4}{7}{Labeling process described in Section~\ref {Subsec:pseudo_er}: (a)~An image in the training dataset. (b)~Region $\Omega _E$. (c)~Manually selected regions. (d)~The labeled image obtained from~(c) by the dilation. \relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces First row: Input images. Second row: $\mathcal  {P}_0$ obatined from the neural network. Third row: Pseudo edge-region $\mathcal  {P}$ with boundaries of landmarks. Fourth row: Contours on standby at a distance from $\mathcal  {P}$. Fifth row: Acquired contours. \relax }}{8}{figure.caption.5}\protected@file@percent }
\newlabel{Fig:pre_er}{{5}{8}{First row: Input images. Second row: $\PER _0$ obatined from the neural network. Third row: Pseudo edge-region $\PER $ with boundaries of landmarks. Fourth row: Contours on standby at a distance from $\PER $. Fifth row: Acquired contours. \relax }{figure.caption.5}{}}
\citation{Park:2014:SRM}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Segmentation using active contours}{9}{subsection.3.2}\protected@file@percent }
\newlabel{Subsec:SegLevelset}{{3.2}{9}{Segmentation using active contours}{subsection.3.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Acquiring initial contours}{9}{subsubsection.3.2.1}\protected@file@percent }
\newlabel{Subsec:initial_contours}{{3.2.1}{9}{Acquiring initial contours}{subsubsection.3.2.1}{}}
\newlabel{Def:CompeteBalloon}{{3.1}{9}{Acquiring initial contours}{equation.3.1}{}}
\newlabel{Eq:evolv_init}{{3.2}{9}{Acquiring initial contours}{equation.3.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}Segmentation using active contours}{9}{subsubsection.3.2.2}\protected@file@percent }
\newlabel{Subsec:segmentation}{{3.2.2}{9}{Segmentation using active contours}{subsubsection.3.2.2}{}}
\newlabel{Eq:proposed}{{3.3}{9}{Segmentation using active contours}{equation.3.3}{}}
\citation{Park:2014:SRM}
\citation{Zeileis:2009:escaping}
\citation{SUSSMAN:1994}
\citation{T000}
\citation{T001}
\citation{T002}
\citation{T003}
\citation{T004}
\citation{T005}
\citation{T006}
\citation{T007}
\citation{T008}
\citation{T009}
\citation{T010}
\citation{T011}
\citation{T012}
\citation{T013}
\citation{T017}
\citation{T018}
\citation{T019}
\citation{T020}
\citation{He:2015:ResNet}
\citation{Krizhevsky:2012:ImageNet}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Identification of tooth and non-tooth regions}{10}{subsection.3.3}\protected@file@percent }
\newlabel{Subsec:regClass}{{3.3}{10}{Identification of tooth and non-tooth regions}{subsection.3.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Experimental results and numerical aspect}{10}{section.4}\protected@file@percent }
\newlabel{Sec:result}{{4}{10}{Experimental results and numerical aspect}{section.4}{}}
\newlabel{Fig:proposed}{{3.2.2}{11}{Segmentation using active contours}{figure.caption.6}{}}
\citation{Zhang:2018:BCE}
\citation{Kingma:2017}
\citation{Na:2014LteethMorph}
\citation{Na:2014LteethMorph}
\citation{He:2018:MRCNN}
\citation{Pham:2020}
\citation{Zhu:2020:teethMaskrcnn}
\citation{Detectron2018}
\citation{Russell:2007:labelme}
\citation{T000}
\citation{T008}
\citation{T005}
\citation{T018}
\citation{T013}
\citation{T001}
\citation{Na:2014LteethMorph}
\citation{He:2018:MRCNN}
\citation{Zhu:2020:teethMaskrcnn}
\citation{Kim:2020}
\citation{T000}
\citation{T008}
\citation{T005}
\citation{T018}
\citation{T013}
\citation{T001}
\citation{Na:2014LteethMorph}
\citation{He:2018:MRCNN}
\citation{Zhu:2020:teethMaskrcnn}
\citation{Kim:2020}
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusion}{12}{section.5}\protected@file@percent }
\newlabel{Sec:Conclusion}{{5}{12}{Conclusion}{section.5}{}}
\newlabel{Fig:na2014}{{7(b)}{13}{MWA\relax }{figure.caption.7}{}}
\newlabel{sub@Fig:na2014}{{(b)}{13}{MWA\relax }{figure.caption.7}{}}
\newlabel{Fig:mrcnn}{{7(c)}{13}{MRCNN\relax }{figure.caption.7}{}}
\newlabel{sub@Fig:mrcnn}{{(c)}{13}{MRCNN\relax }{figure.caption.7}{}}
\newlabel{Fig:mrcnn_w}{{7(d)}{13}{MRCNN2\relax }{figure.caption.7}{}}
\newlabel{sub@Fig:mrcnn_w}{{(d)}{13}{MRCNN2\relax }{figure.caption.7}{}}
\newlabel{Fig:ours}{{7(e)}{13}{Our algorithm\relax }{figure.caption.7}{}}
\newlabel{sub@Fig:ours}{{(e)}{13}{Our algorithm\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces  Segmented results of several methods for images\nobreakspace  {}\cite  {T000,T008,T005,T018,T013,T001}. MWA in (b) is the modified watershed algorithm\nobreakspace  {}\cite  {Na:2014LteethMorph}. MRCNN and MRCNN2 are methods based in Mask R-CNN in\nobreakspace  {}\cite  {He:2018:MRCNN,Zhu:2020:teethMaskrcnn} and\nobreakspace  {}\cite  {Kim:2020}, respectively. In (e), the results using our algorithm are presented. \relax }}{13}{figure.caption.7}\protected@file@percent }
\newlabel{Fig:results}{{7}{13}{Segmented results of several methods for images~\cite {T000,T008,T005,T018,T013,T001}. MWA in (b) is the modified watershed algorithm~\cite {Na:2014LteethMorph}. MRCNN and MRCNN2 are methods based in Mask R-CNN in~\cite {He:2018:MRCNN,Zhu:2020:teethMaskrcnn} and~\cite {Kim:2020}, respectively. In (e), the results using our algorithm are presented. \relax }{figure.caption.7}{}}
\citation{Zhang:2020:ResNeSt}
\citation{Zhang:2020:ResNeSt}
\citation{He:2015:ResNet}
\citation{He:2019:ResNetTrick}
\citation{Zhang:2020:ResNeSt}
\citation{He:2015:ResNet}
\citation{He:2019:ResNetTrick}
\bibstyle{siam}
\bibdata{bibliography}
\@writefile{toc}{\contentsline {section}{\numberline {A}Structure of neural network}{14}{appendix.A}\protected@file@percent }
\newlabel{App:neural_net}{{A}{14}{Structure of neural network}{appendix.A}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces \small  {The structure of the neural network: ResNeSt-50\nobreakspace  {}\cite  {Zhang:2020:ResNeSt} + upscale module. Overall, each rectangle and each bold arrow represent an intermediate result (or input) and an operation, respectively. The number at the top of each rectangle indicates the number of channels. If there is a number in the square above the arrow, it means that the arrow repeats that number. The operation types are color-specific and are listed in the lower-right legend. All arrows have batch normalization\nobreakspace  {}(BN) after the operation with two exceptions in (b):\nobreakspace  {}global average pooling\nobreakspace  {}(GAP) and fully connected layers marked with thin lines. The types of the activation functions are indicated by the shape of arrowheads and are also listed in the legend. In the legend, there are notations $/$ and $+$, which mean stride and padding of the operation with the following number, respectively. All bilinear upscalings are applied with scale factor $2$. There are a total of $7$ RNS-$m$ blocks in\nobreakspace  {}(a). For those arrows, $m$ is $64$, $128$, $128$, $256$, $256$, $512$, $512$ in that order. When $c \neq  m$ in (b), a modification occurs in RNS-$m$ as same as downsampling layers in ResNet\nobreakspace  {}\cite  {He:2015:ResNet,He:2019:ResNetTrick}; MOD1 in the legend is added after the first layer and the dashed identity connection changes to MOD2 in the legend. }\relax }}{15}{figure.caption.8}\protected@file@percent }
\newlabel{Fig:network}{{8}{15}{\small {The structure of the neural network: ResNeSt-50~\cite {Zhang:2020:ResNeSt} + upscale module. Overall, each rectangle and each bold arrow represent an intermediate result (or input) and an operation, respectively. The number at the top of each rectangle indicates the number of channels. If there is a number in the square above the arrow, it means that the arrow repeats that number. The operation types are color-specific and are listed in the lower-right legend. All arrows have batch normalization~(BN) after the operation with two exceptions in (b):~global average pooling~(GAP) and fully connected layers marked with thin lines. The types of the activation functions are indicated by the shape of arrowheads and are also listed in the legend. In the legend, there are notations $/$ and $+$, which mean stride and padding of the operation with the following number, respectively. All bilinear upscalings are applied with scale factor $2$. There are a total of $7$ RNS-$m$ blocks in~(a). For those arrows, $m$ is $64$, $128$, $128$, $256$, $256$, $512$, $512$ in that order. When $c \neq m$ in (b), a modification occurs in RNS-$m$ as same as downsampling layers in ResNet~\cite {He:2015:ResNet,He:2019:ResNetTrick}; MOD1 in the legend is added after the first layer and the dashed identity connection changes to MOD2 in the legend. }\relax }{figure.caption.8}{}}
\gdef \@abspage@last{15}
