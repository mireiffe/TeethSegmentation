\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{Kass:1988:Snakes}
\citation{Xu:1997:GVF}
\citation{Caselles:1997:GAC}
\citation{Chan:2001:chanvese}
\citation{Yuan:2020:teethParanomic}
\citation{Naumovich:2015:teethCT3D}
\citation{Said:2006:teethxray}
\citation{Shah:2006:teethautoseg}
\citation{Na:2014LteethMorph}
\citation{Vincent:1991:watershed}
\citation{WU:2016}
\citation{Dollar:2006:BEL}
\citation{Kim:2020}
\citation{Pham:2020}
\citation{Zhu:2020:teethMaskrcnn}
\citation{He:2018:MRCNN}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\newlabel{Sec:Introduction}{{1}{1}{Introduction}{section.1}{}}
\citation{Pretty:2001:forensic}
\citation{Yuan:2020:teethParanomic}
\citation{Naumovich:2015:teethCT3D}
\citation{WU:2016}
\citation{Pretty:2001:forensic}
\citation{Shah:2006:teethautoseg}
\citation{Hahn:2006}
\citation{Hahn:2010:GADF}
\citation{Hahn:2010:GADF}
\@writefile{toc}{\contentsline {section}{\numberline {2}GADF, edge-regions, and segmentation}{2}{section.2}\protected@file@percent }
\newlabel{Sec:er_teeth}{{2}{2}{GADF, edge-regions, and segmentation}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}GADF}{2}{subsection.2.1}\protected@file@percent }
\newlabel{Subsec:GADF}{{2.1}{2}{GADF}{subsection.2.1}{}}
\newlabel{Def:gadf}{{2.1}{2}{GADF}{equation.2.1}{}}
\citation{Hahn:2006}
\citation{Hahn:2010:GADF}
\citation{Hahn:2010:GADF}
\citation{Hahn:2006}
\citation{Hahn:2010:GADF}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Edge-regions}{3}{subsection.2.2}\protected@file@percent }
\newlabel{Subsec:edge-regions}{{2.2}{3}{Edge-regions}{subsection.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Active contour model}{3}{subsection.2.3}\protected@file@percent }
\newlabel{Subsec:active_contour}{{2.3}{3}{Active contour model}{subsection.2.3}{}}
\newlabel{Eq:ac_gadf}{{2.2}{3}{Active contour model}{equation.2.2}{}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{Fig:edge_regions_4}{{1(c)}{4}{Refined $\ome $\relax }{figure.caption.1}{}}
\newlabel{sub@Fig:edge_regions_4}{{(c)}{4}{Refined $\ome $\relax }{figure.caption.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces  (a) Several teeth images. Synthetic image, teeth image without light reflections, and teeth image with light reflections are shown from top to bottom. (b) Edge-region candidates $\Omega _E$ of the left images. (c) Refined $\Omega _E$ using component size and image intensity. \relax }}{4}{figure.caption.1}\protected@file@percent }
\newlabel{Fig:edge_regions}{{1}{4}{(a) Several teeth images. Synthetic image, teeth image without light reflections, and teeth image with light reflections are shown from top to bottom. (b) Edge-region candidates $\ome $ of the left images. (c) Refined $\ome $ using component size and image intensity. \relax }{figure.caption.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces From left to right, the multiple contours evolving by\nobreakspace  {}\textup  {\hbox {\mathsurround \z@ \normalfont (\ignorespaces \ref  {Eq:ac_gadf}\unskip \@@italiccorr )}} is shown over time. The evolution steps are presented from the initial-state to the steady-state. There are three active contours and different color means different contour. Observe that if a contour meets an edge-region, it drags into the edge-region along the GADF, and if the edge-region encloses regions, the contour stops at the boundary of these regions so that there may occur unsegmented regions. However, a contour faces an end of region with non-closed shape, the contour intrudes the region and eventually encroaches. \relax }}{4}{figure.caption.2}\protected@file@percent }
\newlabel{Fig:evolution}{{2}{4}{From left to right, the multiple contours evolving by~\eqref {Eq:ac_gadf} is shown over time. The evolution steps are presented from the initial-state to the steady-state. There are three active contours and different color means different contour. Observe that if a contour meets an edge-region, it drags into the edge-region along the GADF, and if the edge-region encloses regions, the contour stops at the boundary of these regions so that there may occur unsegmented regions. However, a contour faces an end of region with non-closed shape, the contour intrudes the region and eventually encroaches. \relax }{figure.caption.2}{}}
\citation{SpecRemoval:2018}
\citation{SpecRemoval:2020}
\citation{SpecRemoval:2016}
\citation{SpecRemoval:2015}
\citation{Shafer:1985:colorsep}
\citation{LeeRemoval:2010}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Light reflections in teeth images}{5}{subsection.2.4}\protected@file@percent }
\newlabel{Subsec:light_reflection}{{2.4}{5}{Light reflections in teeth images}{subsection.2.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Proposed Method}{5}{section.3}\protected@file@percent }
\newlabel{Sec:PM}{{3}{5}{Proposed Method}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Obtaining pseudo edge-region from a neural network}{5}{subsection.3.1}\protected@file@percent }
\newlabel{Subsec:pseudo_er}{{3.1}{5}{Obtaining pseudo edge-region from a neural network}{subsection.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Algorithm flowchart: (a) Data labeling and training process. (b) Segmentation process. \relax }}{6}{figure.caption.3}\protected@file@percent }
\newlabel{Fig:flowchart}{{3}{6}{Algorithm flowchart: (a) Data labeling and training process. (b) Segmentation process. \relax }{figure.caption.3}{}}
\citation{Zhang:2020:ResNeSt}
\citation{Zhang:2018:BCE}
\citation{T023}
\citation{T023}
\newlabel{Fig:4a}{{4(a)}{7}{A training image \cite {T023}\relax }{figure.caption.4}{}}
\newlabel{sub@Fig:4a}{{(a)}{7}{A training image \cite {T023}\relax }{figure.caption.4}{}}
\newlabel{Fig:4b}{{4(b)}{7}{$\ome $\relax }{figure.caption.4}{}}
\newlabel{sub@Fig:4b}{{(b)}{7}{$\ome $\relax }{figure.caption.4}{}}
\newlabel{Fig:4c}{{4(c)}{7}{Selected regions $\oms $\relax }{figure.caption.4}{}}
\newlabel{sub@Fig:4c}{{(c)}{7}{Selected regions $\oms $\relax }{figure.caption.4}{}}
\newlabel{Fig:4d}{{4(d)}{7}{Labeled image $Y$\relax }{figure.caption.4}{}}
\newlabel{sub@Fig:4d}{{(d)}{7}{Labeled image $Y$\relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces  Labeling process described in Section\nobreakspace  {}\ref  {Subsec:pseudo_er}: (a) An image in the training dataset. (b) The region $\Omega _E$. (c) Manually selected regions. (d) The labeled image obtained from (c) by the dilation. \relax }}{7}{figure.caption.4}\protected@file@percent }
\newlabel{Fig:labeling}{{4}{7}{Labeling process described in Section~\ref {Subsec:pseudo_er}: (a) An image in the training dataset. (b) The region $\Omega _E$. (c) Manually selected regions. (d) The labeled image obtained from (c) by the dilation. \relax }{figure.caption.4}{}}
\newlabel{Def:omcc}{{3.1}{7}{Obtaining pseudo edge-region from a neural network}{equation.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces First row: Input images. Second row: Pseudo edge-region obatined from the neural network. Third row: Boundaries of landmarks obtained for the non-tooth regions of $\mathcal  {P}$. Fourth row: Acquired initial contours. The green color means $\Omega _T$ and the red color means $\Omega _N$. \relax }}{8}{figure.caption.5}\protected@file@percent }
\newlabel{Fig:pre_er}{{5}{8}{First row: Input images. Second row: Pseudo edge-region obatined from the neural network. Third row: Boundaries of landmarks obtained for the non-tooth regions of $\PER $. Fourth row: Acquired initial contours. The green color means $\omt $ and the red color means $\omn $. \relax }{figure.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Active contour model and initial contours}{9}{subsection.3.2}\protected@file@percent }
\newlabel{Subsec:SegLevelset}{{3.2}{9}{Active contour model and initial contours}{subsection.3.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Acquiring initial contours}{9}{subsubsection.3.2.1}\protected@file@percent }
\newlabel{Subsec:initial_contours}{{3.2.1}{9}{Acquiring initial contours}{subsubsection.3.2.1}{}}
\newlabel{Def:CompeteBalloon}{{3.2}{9}{Acquiring initial contours}{equation.3.2}{}}
\citation{Park:2014:SRM}
\citation{Park:2014:SRM}
\citation{Zeileis:2009:escaping}
\newlabel{Eq:evolv_init}{{3.3}{10}{Acquiring initial contours}{equation.3.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}Segmentation using active contours}{10}{subsubsection.3.2.2}\protected@file@percent }
\newlabel{Subsec:segmentation}{{3.2.2}{10}{Segmentation using active contours}{subsubsection.3.2.2}{}}
\newlabel{Eq:proposed}{{3.4}{10}{Segmentation using active contours}{equation.3.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Identification of tooth and non-tooth regions}{10}{subsection.3.3}\protected@file@percent }
\newlabel{Subsec:regClass}{{3.3}{10}{Identification of tooth and non-tooth regions}{subsection.3.3}{}}
\citation{SUSSMAN:1994}
\citation{He:2015:ResNet}
\citation{Krizhevsky:2012:ImageNet}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces  Two regions $\mathcal  {P}$ (white) and $\mathcal  {R}$ (yellow) are shown in the leftmost image. From second left to right, contour evolution using\nobreakspace  {}\textup  {\hbox {\mathsurround \z@ \normalfont (\ignorespaces \ref  {Eq:proposed}\unskip \@@italiccorr )}} is presented. Different color means different contour. We will focus on the red and green contours among them. As same as Figure\nobreakspace  {}\ref  {Fig:evolution}, if contours meet $\mathcal  {R}$, then they drag into $\mathcal  {R}$ along the GADF. The important part is around the center of $\mathcal  {P}$ that does not contains $\mathcal  {R}$. In there, the upper part of the green contour cannot advance further at the boundary of the $\mathcal  {P}$, but in the lower part, the contour constantly moves outward. The reason why the upper part of green contour does not move is because $F_{s,\,i}$ indicates boundary on there, contrary on the lower part. In other side, the red contour constantly moves everywhere. Consequently, the segmenting line is formed on the left boundary of $\mathcal  {P}$ in the upper part, but formed inner side of $\mathcal  {P}$ in the lower part. \relax }}{11}{figure.caption.6}\protected@file@percent }
\newlabel{Fig:proposed}{{6}{11}{Two regions $\PER $ (white) and $\ER $ (yellow) are shown in the leftmost image. From second left to right, contour evolution using~\eqref {Eq:proposed} is presented. Different color means different contour. We will focus on the red and green contours among them. As same as Figure~\ref {Fig:evolution}, if contours meet $\ER $, then they drag into $\ER $ along the GADF. The important part is around the center of $\PER $ that does not contains $\ER $. In there, the upper part of the green contour cannot advance further at the boundary of the $\PER $, but in the lower part, the contour constantly moves outward. The reason why the upper part of green contour does not move is because $\fsi $ indicates boundary on there, contrary on the lower part. In other side, the red contour constantly moves everywhere. Consequently, the segmenting line is formed on the left boundary of $\PER $ in the upper part, but formed inner side of $\PER $ in the lower part. \relax }{figure.caption.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Experimental results and numerical aspect}{11}{section.4}\protected@file@percent }
\newlabel{Sec:result}{{4}{11}{Experimental results and numerical aspect}{section.4}{}}
\citation{T000}
\citation{T001}
\citation{T002}
\citation{T003}
\citation{T004}
\citation{T005}
\citation{T006}
\citation{T007}
\citation{T008}
\citation{T009}
\citation{T010}
\citation{T011}
\citation{T012}
\citation{T013}
\citation{T017}
\citation{T018}
\citation{T019}
\citation{T020}
\citation{Zhang:2018:BCE}
\citation{Kingma:2017}
\citation{Na:2014LteethMorph}
\citation{Na:2014LteethMorph}
\citation{He:2018:MRCNN}
\citation{Pham:2020}
\citation{Zhu:2020:teethMaskrcnn}
\citation{Russell:2007:labelme}
\citation{Na:2014LteethMorph}
\citation{Na:2014LteethMorph}
\citation{He:2018:MRCNN}
\citation{Zhu:2020:teethMaskrcnn}
\citation{He:2018:MRCNN}
\citation{Zhu:2020:teethMaskrcnn}
\citation{Kim:2020}
\citation{Kim:2020}
\citation{T000}
\citation{T008}
\citation{T005}
\citation{T018}
\citation{T013}
\citation{T001}
\citation{Na:2014LteethMorph}
\citation{Zhu:2020:teethMaskrcnn}
\citation{Kim:2020}
\citation{T000}
\citation{T008}
\citation{T005}
\citation{T018}
\citation{T013}
\citation{T001}
\citation{Na:2014LteethMorph}
\citation{Zhu:2020:teethMaskrcnn}
\citation{Kim:2020}
\newlabel{Fig:na2014}{{7(b)}{13}{MWA \cite {Na:2014LteethMorph}\relax }{figure.caption.7}{}}
\newlabel{sub@Fig:na2014}{{(b)}{13}{MWA \cite {Na:2014LteethMorph}\relax }{figure.caption.7}{}}
\newlabel{Fig:mrcnn}{{7(c)}{13}{MRCNN~\cite {He:2018:MRCNN,Zhu:2020:teethMaskrcnn}\relax }{figure.caption.7}{}}
\newlabel{sub@Fig:mrcnn}{{(c)}{13}{MRCNN~\cite {He:2018:MRCNN,Zhu:2020:teethMaskrcnn}\relax }{figure.caption.7}{}}
\newlabel{Fig:mrcnn_w}{{7(d)}{13}{MRCNN2~\cite {Kim:2020}\relax }{figure.caption.7}{}}
\newlabel{sub@Fig:mrcnn_w}{{(d)}{13}{MRCNN2~\cite {Kim:2020}\relax }{figure.caption.7}{}}
\newlabel{Fig:ours}{{7(e)}{13}{Our algorithm\relax }{figure.caption.7}{}}
\newlabel{sub@Fig:ours}{{(e)}{13}{Our algorithm\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces  Segmented results of several methods for input images in (a)\nobreakspace  {}\cite  {T000,T008,T005,T018,T013,T001}. The MWA in (b) is modified watershed algorithm\nobreakspace  {}\cite  {Na:2014LteethMorph}. MRCNN and MRCNN2 are methods in papers\nobreakspace  {}\cite  {Zhu:2020:teethMaskrcnn} and\nobreakspace  {}\cite  {Kim:2020}, respectively. In (e), results using our algorithm is presented. \relax }}{13}{figure.caption.7}\protected@file@percent }
\newlabel{Fig:results}{{7}{13}{Segmented results of several methods for input images in (a)~\cite {T000,T008,T005,T018,T013,T001}. The MWA in (b) is modified watershed algorithm~\cite {Na:2014LteethMorph}. MRCNN and MRCNN2 are methods in papers~\cite {Zhu:2020:teethMaskrcnn} and~\cite {Kim:2020}, respectively. In (e), results using our algorithm is presented. \relax }{figure.caption.7}{}}
\citation{Zhang:2020:ResNeSt}
\citation{He:2015:ResNet}
\citation{He:2019:ResNetTrick}
\citation{Zhang:2020:ResNeSt}
\citation{He:2015:ResNet}
\citation{He:2019:ResNetTrick}
\bibstyle{siam}
\bibdata{bibliography}
\bibcite{T000}{1}
\bibcite{T008}{2}
\bibcite{Caselles:1997:GAC}{3}
\bibcite{Chan:2001:chanvese}{4}
\bibcite{Dollar:2006:BEL}{5}
\bibcite{T005}{6}
\bibcite{SpecRemoval:2018}{7}
\bibcite{Hahn:2006}{8}
\bibcite{Hahn:2010:GADF}{9}
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusion}{14}{section.5}\protected@file@percent }
\newlabel{Sec:Conclusion}{{5}{14}{Conclusion}{section.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A}Structure of neural network}{14}{appendix.A}\protected@file@percent }
\newlabel{App:neural_net}{{A}{14}{Structure of neural network}{appendix.A}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces \small  {The structure of the neural network: ResNeSt\nobreakspace  {}\cite  {Zhang:2020:ResNeSt} + upscale module. Overall, each rectangle and each bold arrow represent an intermediate result (or input) and a operation, respectively. The number at the top of the rectangle indicates the number of channels. Among the arrows, if there is a number in the square above the arrow, that means the arrow is repeated as many times as that number. The operation types are color-specific and are listed in the lower-right legend. Every arrow has a batch normalization (BN) after the operation with only two exceptions in (b): the global average pooling (GAP) and fully connected layers marked with thin line width. The type of the activation functions are indicated by the shape of arrowheads and are also listed in the legend. In the legend, there are notations $/$ and $+$, which mean stride and padding of the operation with the following number, respectively. All the bilinear upscalings are applied with scale factor $2$. There are totally $7$ RNS-$m$ blocks in\nobreakspace  {}(a). For that arrows, $m$ is $64$, $128$, $128$, $256$, $256$, $512$, $512$ in order. When $c \neq  m$ in (b), a modification occurs in RNS--$m$ as same as downsampling layers in the ResNet\nobreakspace  {}\cite  {He:2015:ResNet,He:2019:ResNetTrick}: the MOD1 in the legend is added after the first layer, and the dashed identity connection changes to MOD2 in the legend. }\relax }}{15}{figure.caption.8}\protected@file@percent }
\newlabel{Fig:network}{{8}{15}{\small {The structure of the neural network: ResNeSt~\cite {Zhang:2020:ResNeSt} + upscale module. Overall, each rectangle and each bold arrow represent an intermediate result (or input) and a operation, respectively. The number at the top of the rectangle indicates the number of channels. Among the arrows, if there is a number in the square above the arrow, that means the arrow is repeated as many times as that number. The operation types are color-specific and are listed in the lower-right legend. Every arrow has a batch normalization (BN) after the operation with only two exceptions in (b): the global average pooling (GAP) and fully connected layers marked with thin line width. The type of the activation functions are indicated by the shape of arrowheads and are also listed in the legend. In the legend, there are notations $/$ and $+$, which mean stride and padding of the operation with the following number, respectively. All the bilinear upscalings are applied with scale factor $2$. There are totally $7$ RNS-$m$ blocks in~(a). For that arrows, $m$ is $64$, $128$, $128$, $256$, $256$, $512$, $512$ in order. When $c \neq m$ in (b), a modification occurs in RNS--$m$ as same as downsampling layers in the ResNet~\cite {He:2015:ResNet,He:2019:ResNetTrick}: the MOD1 in the legend is added after the first layer, and the dashed identity connection changes to MOD2 in the legend. }\relax }{figure.caption.8}{}}
\bibcite{He:2018:MRCNN}{10}
\bibcite{He:2015:ResNet}{11}
\bibcite{He:2019:ResNetTrick}{12}
\bibcite{Kass:1988:Snakes}{13}
\bibcite{Kim:2020}{14}
\bibcite{Kingma:2017}{15}
\bibcite{Krizhevsky:2012:ImageNet}{16}
\bibcite{LeeRemoval:2010}{17}
\bibcite{SpecRemoval:2020}{18}
\bibcite{Yuan:2020:teethParanomic}{19}
\bibcite{T018}{20}
\bibcite{Na:2014LteethMorph}{21}
\bibcite{Naumovich:2015:teethCT3D}{22}
\bibcite{T013}{23}
\bibcite{Park:2014:SRM}{24}
\bibcite{T001}{25}
\bibcite{Pretty:2001:forensic}{26}
\bibcite{Russell:2007:labelme}{27}
\bibcite{Said:2006:teethxray}{28}
\bibcite{Shafer:1985:colorsep}{29}
\bibcite{Shah:2006:teethautoseg}{30}
\bibcite{T017}{31}
\bibcite{T023}{32}
\bibcite{SpecRemoval:2016}{33}
\bibcite{SUSSMAN:1994}{34}
\bibcite{Pham:2020}{35}
\bibcite{Vincent:1991:watershed}{36}
\bibcite{WU:2016}{37}
\bibcite{Xu:1997:GVF}{38}
\bibcite{SpecRemoval:2015}{39}
\bibcite{Zeileis:2009:escaping}{40}
\bibcite{Zhang:2020:ResNeSt}{41}
\bibcite{Zhang:2018:BCE}{42}
\bibcite{Zhu:2020:teethMaskrcnn}{43}
\gdef \@abspage@last{18}
